[
  {
    "objectID": "PS2_key.html",
    "href": "PS2_key.html",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "Consider a diagnostic test designed to determine whether a piece of medical equipment is faulty. The diagnostic test has a sensitivity of 0.9 and specificity of 0.9. If the estimated percentage of faulty equipment fleet is 1%, what is the probability that a randomly selected piece of equipment is faulty given that it tested positive? [2pts]\n\n\n\n\n\n\n\nAnswer\n\n\n\nThe base rate is 0.01, Sensitivity is 0.9, Specificity is 0.9. The probability that the equipment is faulty given a positive test is a positive predictive value.\n\\[\nPPV = \\frac{sens*BR}{sens*BR + (1-spec)(1-BR)}\n\\]\n\nPPV &lt;- (0.9)*(0.01)/((0.9*0.01)+(1-0.9)*(1-0.01))\nPPV\n\n[1] 0.08333333\n\n\n\n\n\nWhat is the sample space of a two-sided coin that was tossed three times? [1pt.]\n\n\n\n\n\n\n\nAnswer\n\n\n\nThe answer should include all possible outcomes after tossing a two-sided coin three times. H: Heads, T: Tails\n\nHHH\nHTT\nTHT\nTTH\nTHH\nHTH\nHHT\nTTT\n\nHence the sample space can be written as {HHH, HTT, THT,TTH,THH,HTH,HHT,TTT}\n\n\n\nAn experiment has three possible outcomes, A, B, and C, only one of which can occur at a time. If outcome B is twice as likely as outcome A and if outcome C is thrice as likely as outcome A, what are the marginal probabilities of each outcome (P(A), P(B), P(C))? (Hint: The second axiom of probability states that the sum of the probabilities of the mutually exclusive events is equal to 1.) [3pts]\n\n\n\n\n\n\n\nAnswer\n\n\n\nFrom the hint, \\(P(A)+P(B)+P(C) = 1\\). We also know that \\(P(B) = 2P(A)\\) and \\(P(C) = 3P(A)\\). Substituting it to the 2nd axiom of probability,\n\\[\n3P(A) + 2P(A) + P(A) = 1\n\\] \\[\n6P(A) = 1; P(A) = 1/6\n\\]\nIt follows that \\(P(B) = 2P(A) = 2/6 = 1/3\\), \\(P(C) = 3P(A) = 3/6 = 1/2\\).\n\n\n\nThe results of a feasibility study suggest that the probability of randomly selecting an individual who uses AI is 55%. Among those who use AI, the probability of using AI for health-related advice is 23%. What is the probability that a randomly selected individual uses AI for health-related advice? [2pts]\n\n\n\n\n\n\n\nAnswer\n\n\n\nP(AI and health advice) can be calculated using the multiplication rule with the following values: \\(P(AI) = 0.55\\), \\(P(HA | AI) = 0.23\\). Then,\n\\[\nP(AI \\cap HA) = P(HA|AI)P(AI) = (0.55)(0.23)\n\\]\nThe resulting value of \\(P(AI \\cap HA) =\\) 0.1265\n\n\n\nAmong 1000 university students, 247 reported to be current smokers, 312 reported to have symptoms of binge drinking, and 59 reported to being current smokers and having symptoms of binge drinking. What is the probability that a randomly selected student out of the 1000 university students is a current smoker or has symptoms of binge drinking? [2pts]\n\n\n\n\n\n\n\nAnswer\n\n\n\nWe can solve for P(Smoker OR Binge) using the addition rule.\n\\[\nP(S \\cup B) = P(S) + P(B) - P(S \\cap B) = 247/1000+312/1000 - 59/1000\n\\]\nThe resulting value of \\(P(S \\cup B)=\\) 0.5"
  },
  {
    "objectID": "problemsets.html",
    "href": "problemsets.html",
    "title": "EAB 703 Problem Set Keys",
    "section": "",
    "text": "This website provides the answer keys for the Problem Sets given in EAB 703-1002 taught by Dr. Miguel Fudolig.",
    "crumbs": [
      "Problem Sets"
    ]
  },
  {
    "objectID": "lecture5.html#activity",
    "href": "lecture5.html#activity",
    "title": "Sampling Distributions",
    "section": "Activity",
    "text": "Activity\nLet us use the “Sampling Words” applet through this link. Suppose we are interested in calculating the average word length of different samples of 10 words from Beyonce’s Crazy in Love.\n\nDid we get the same average length for all samples?"
  },
  {
    "objectID": "lecture5.html#sampling-distributions",
    "href": "lecture5.html#sampling-distributions",
    "title": "Sampling Distributions",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\nRepeated samples will yield different values for the statistics.\n\n\n\n\n\n\nNote\n\n\nWe have to view statistics as the sample mean \\(\\bar{x}\\) and sample proportion \\(\\hat{p}\\) as random variables. The probability distribution of these statistics are called sampling distributions. These distributions enable us to:\n\nAnswer probability questions about sample statistics\nProvide the necessary theory for some statistical inference tests."
  },
  {
    "objectID": "lecture5.html#sampling-distributions-1",
    "href": "lecture5.html#sampling-distributions-1",
    "title": "Sampling Distributions",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\nThe sampling distribution of a statistic is the distribution of all possible values that can be assumed by some statistic computed from samples of the same size from the population.\n\n\n\n\n\n\nNote\n\n\nWe are usually interested in knowing the functional form (refer to distributions discussed in Chapter 4), mean, and variance."
  },
  {
    "objectID": "lecture5.html#sampling-from-gaussian-distributed-populations",
    "href": "lecture5.html#sampling-from-gaussian-distributed-populations",
    "title": "Sampling Distributions",
    "section": "Sampling from Gaussian-distributed populations",
    "text": "Sampling from Gaussian-distributed populations\nFor a sample with size \\(n\\) that comes from a Gaussian-distributed population with mean \\(\\mu\\) and variance \\(\\sigma^2\\), i.e. the samples \\(X_1,X_2,...,X_n\\) are all independent and identically distributed such that \\(X_i \\sim N(\\mu,\\sigma^2)\\), the sample mean can be defined as:\n\\[\n\\bar{X} = \\frac{X_1 + X_2 + ... + X_n}{n}\n\\]\nThe probability distribution of the sample mean, also known as the sampling distribution of the sample mean can be expressed as:\n\\[\n\\bar{X} \\sim N(\\mu, \\frac{\\sigma^2}{n})\n\\]"
  },
  {
    "objectID": "lecture5.html#implications",
    "href": "lecture5.html#implications",
    "title": "Sampling Distributions",
    "section": "Implications",
    "text": "Implications\n\n\n\n\n\n\nImportant\n\n\nThe mean of the sampling distribution, \\(\\mu_{\\bar{X}}\\) is equal to the population mean, while the variance, \\(\\sigma^2_{\\bar{X}}\\) is reduced by a factor of the sample size \\(n\\).\nThe standard deviation of the sampling distribution can be calculated by taking the square root of the variance of the distribution, \\(\\sqrt{\\frac{\\sigma^2}{n}} = \\frac{\\sigma}{\\sqrt{n}}\\). This is referred to as the standard error of the sample mean."
  },
  {
    "objectID": "lecture5.html#standardization",
    "href": "lecture5.html#standardization",
    "title": "Sampling Distributions",
    "section": "Standardization",
    "text": "Standardization\nThe sample mean can also be standardized based on the properties of the sampling distribution. The sample mean \\(\\bar{X}\\) can be transformed into a random variable \\(Z\\) such that \\(Z \\sim N(0,1)\\).\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}}\n\\] In addition,\n\\[\nP(\\bar{X} \\leq \\bar{x}) = P(Z \\leq \\frac{\\bar{x} - \\mu}{\\sigma/\\sqrt{n}}) = P(Z \\leq z)\n\\]"
  },
  {
    "objectID": "lecture5.html#sampling-from-non-gaussian-populations",
    "href": "lecture5.html#sampling-from-non-gaussian-populations",
    "title": "Sampling Distributions",
    "section": "Sampling from Non-Gaussian Populations",
    "text": "Sampling from Non-Gaussian Populations\nThe sampling distribution previously derived could also apply to samples from non-Gaussian populations under certain conditions. These conditions are provided by the central limit theorem.\n\n\n\n\n\n\n\nCentral Limit Theorem (CLT)\n\n\nGiven a population of any non-Gaussian functional form with a mean \\(\\mu\\) and finite variance \\(\\sigma^2\\), the sampling distribution of \\(\\bar{x}\\) computed from samples of size \\(n\\) from this population, will have mean \\(\\mu\\) and variance \\(\\sigma^2/n\\) and will be approximately Gaussian distributed when the sample size is large.\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nThe rule of thumb for sample means is that a sample size of 30 is satisfactory for the central limit theorem, but this maybe too small for skewed distributions. The Gaussian approximation provided by the CLT becomes better as the sample size increases."
  },
  {
    "objectID": "lecture5.html#example",
    "href": "lecture5.html#example",
    "title": "Sampling Distributions",
    "section": "Example",
    "text": "Example\nSuppose it is known that in a certain large human population cranial length is approximately Gaussian distributed with a mean of 185.6 mm and a standard deviation of 12.7 mm.\n\nQuestionAnswer\n\n\nWhat is the probability that a random sample of size 10 from this population will have a mean greater than 190?\n\n\nWe can use the sampling distribution because we know the sample is from a Gaussian population. The mean of the sampling distribution, \\(\\mu_{\\bar{X}}\\), should be equal to the population mean. Hence, \\(\\mu_{\\bar{X}} = 185.6\\).\nThe standard error, \\(\\sigma_{\\bar{X}}\\), can be calculated using the following formula: \\(\\sigma_{\\bar{X}} = \\sigma/\\sqrt{n} = 12.7/\\sqrt{10} =\\) 4.0161\nUsing the knowledge that \\(\\bar{X} \\sim N(185.6, 12.7/\\sqrt{10})\\), we can use pnorm to calculate the probability that the sample mean is greater than 190.\n\npnorm(190,mean=185.6,sd=12.7/sqrt(10),lower.tail=F)\n\n[1] 0.1366286\n\nz &lt;- (190-185.6)/(12.7/sqrt(10))\npnorm(z,0,1,lower.tail=F)\n\n[1] 0.1366286"
  },
  {
    "objectID": "lecture5.html#example-2",
    "href": "lecture5.html#example-2",
    "title": "Sampling Distributions",
    "section": "Example 2",
    "text": "Example 2\nSuppose the hourly number of customer arrivals at a hospital ED has a Poisson distribution with rate parameter \\(\\lambda=6\\). Every hour for 48 hours, the number of customer arrivals is counted and recorded.\n\nQuestionAnswer\n\n\nUse the CLT to approximate the probability that the average number of arrivals is between 5 and 8.\n\n\nThe data is non-Gaussian, but we will assume that the CLT holds. Recall that for a Poisson distribution, the mean is equal to the variance. Specifically, \\(\\mu=6\\), \\(\\sigma^2 = 6\\), \\(n=48\\). Hence, the mean and the standard error can be expressed as:\n\\[\n\\mu_{\\bar{X}} = 6; \\sigma_{\\bar{X}} = \\sqrt{6/48}\n\\] The probability that the average number of arrivals in the 48-hour period is between 5 and 8 is:\n\npnorm(8,6,sqrt(6/48)) - pnorm(5,6,sqrt(6/48))\n\n[1] 0.9976611"
  },
  {
    "objectID": "lecture5.html#exercise",
    "href": "lecture5.html#exercise",
    "title": "Sampling Distributions",
    "section": "Exercise",
    "text": "Exercise\nThe daily average screen time of elementary school students is assumed to follow a non-Gaussian distribution with 2.6 hours with a standard deviation of 5.3.\n\nQuestionAnswer\n\n\nUse the central limit theorem to calculate the probability that a sample of 250 elementary school students will yield an average screen time between 1.5 hours and 2 hours?\n\n\nThe mean of the sampling distribution is 2.6 hours and the standard error of the mean is \\(5.3/\\sqrt{250} =\\) 0.3352014.\n\npnorm(2,2.6,5.3/sqrt(250)) - pnorm(1.5,2.6,5.3/sqrt(250))\n\n[1] 0.03621341"
  },
  {
    "objectID": "lecture5.html#sample-mean-vs.-difference-between-two-sample-means",
    "href": "lecture5.html#sample-mean-vs.-difference-between-two-sample-means",
    "title": "Sampling Distributions",
    "section": "Sample Mean vs. Difference Between Two Sample Means",
    "text": "Sample Mean vs. Difference Between Two Sample Means\nConsider Populations A and B with the following possible measurements:\nA: {0,1,2}; B:{1,2,3}.\nIf we take a sample with size 2, we can have the following scenario:\nSample A: {0,2}; Sample B: {1,2}\n\n\n\n\n\n\nWarning\n\n\nThe sample mean of Sample A is 1, and the mean of Sample B is 1.5. However, the difference between the sample means is -0.5, which is not a possible value for the sample means of A and B."
  },
  {
    "objectID": "lecture5.html#sampling-from-gaussian-distributed-populations-1",
    "href": "lecture5.html#sampling-from-gaussian-distributed-populations-1",
    "title": "Sampling Distributions",
    "section": "Sampling from Gaussian-distributed populations",
    "text": "Sampling from Gaussian-distributed populations\nWhen sampling from two Gaussian-distributed populations \\(N(\\mu_1,\\sigma_1^2)\\) and \\(N(\\mu_2,\\sigma_2^2)\\), the distribution of the difference between sample means \\(\\bar{X}_1 - \\bar{X}_2\\) is a Gaussian distribution with mean \\(\\mu_1-\\mu_2\\) and variance \\(\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}\\). Mathematically,\n\\[\n\\bar{X}_1 - \\bar{X}_2 \\sim N(\\mu_1-\\mu_2,\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2})\n\\]"
  },
  {
    "objectID": "lecture5.html#standardization-1",
    "href": "lecture5.html#standardization-1",
    "title": "Sampling Distributions",
    "section": "Standardization",
    "text": "Standardization\nSimilar to the sample mean, the difference of the sample means can also be standardized.\n\\[\nZ = \\frac{(\\bar{X}_1 - \\bar{X}_2) - (\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}}\n\\]\nIn addition,\n\\[\nP((\\bar{X}_1 - \\bar{X}_2) \\leq (\\bar{x}_1 - \\bar{x}_2)) = P\\left(Z \\leq \\frac{(\\bar{x}_1 - \\bar{x}_2) - (\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}}\\right)\n\\]"
  },
  {
    "objectID": "lecture5.html#example-1",
    "href": "lecture5.html#example-1",
    "title": "Sampling Distributions",
    "section": "Example",
    "text": "Example\nSuppose it has been established that for a certain type of client the average length of a home visit by a public health nurse is 45 minutes with a standard deviation of 15 minutes, and that for a second type of client the average home visit is 30 minutes long with a standard deviation of 20 minutes.\n\nQuestionAnswer\n\n\nIf a nurse randomly visits 35 clients from the first and 40 from the second population, what is the probability that the average length of home visit will differ between client type one and client type two by 20 or more minutes?\n\n\n\n# Calculate the mean and variance of the sampling distribution first.\n1diff_means &lt;- 45-30\n2diff_var &lt;- 15^2/35 + 20^2/40\n\npnorm(20,diff_means,sqrt(diff_var),lower.tail=F)\n\n# OR An alternative solution\n\n3z &lt;- (20 - diff_means)/sqrt(diff_var)\n\npnorm(z,0,1,lower.tail=F)\n\n\n1\n\nmu_1-mu_2\n\n2\n\nsigma_1^2/n1 + sigma_2^2/n2\n\n3\n\nStandardization method\n\n\n\n\n[1] 0.1086783\n[1] 0.1086783"
  },
  {
    "objectID": "lecture5.html#exercise-1",
    "href": "lecture5.html#exercise-1",
    "title": "Sampling Distributions",
    "section": "Exercise",
    "text": "Exercise\nSuppose the age of two student organizations were normally distributed. Organization A has an average age of 20.5 and a standard deviation of 3.7, while Organization B has an average of 19.7 and a standard deviation of 4.5.\n\nQuestionAnswer\n\n\nIf 50 students were sampled from each organization, what is the probability that the sample from Organization A is older than Organization B by a value between one and two years?\n\n\n\ndiff_means &lt;- 20.5-19.7\ndiff_var &lt;- 4.5^2/50 + 3.7^2/50\n\npnorm(2,diff_means,sqrt(diff_var))-pnorm(1,diff_means,sqrt(diff_var))\n\n[1] 0.3314723\n\n# OR An alternative solution\n\nz1 &lt;- (2 - diff_means)/sqrt(diff_var) \nz2 &lt;- (1 - diff_means)/sqrt(diff_var) \n\npnorm(z1,0,1) - pnorm(z2,0,1)\n\n[1] 0.3314723"
  },
  {
    "objectID": "lecture3.html#objective-probability",
    "href": "lecture3.html#objective-probability",
    "title": "Introduction to Probability",
    "section": "Objective Probability",
    "text": "Objective Probability\nProbability was thought of by statisticians and mathematicians only as an objective phenomenon derived from objective processes.\n\n\n\n\n\n\nNote\n\n\nThere are two categories of objective probability:\n\nclassical/a priori probability\nfrequentist/a posteriori probability",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#classical-probability",
    "href": "lecture3.html#classical-probability",
    "title": "Introduction to Probability",
    "section": "Classical Probability",
    "text": "Classical Probability\nProbabilities for random events related to games of chance can be calculated by the processes of abstract reasoning. Therefore, it is not necessary for these events to happen to compute these probabilities.\n\n\n\n\n\n\n\nClassical/A Priori Probability\n\n\nProbability is defined as follows: If an event can occur in \\(N\\) mutually exclusive and equally likely ways, and if \\(m\\) of these possess a trait \\(E\\), the probability of the occurrence of \\(E\\) is equal to \\(m/N\\).\n\\[\nP(E)= m/N\n\\]\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nAs an example, the probability of getting a three after tossing a fair six-sided die can be calculated by assuming that each of the six sides is equally likely to be observed.\nThe number of outcomes that include a three is 1 out of a total of 6 mutually exclusive outcomes.\nHence, the probability is 1/6.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#frequentist-probability",
    "href": "lecture3.html#frequentist-probability",
    "title": "Introduction to Probability",
    "section": "Frequentist Probability",
    "text": "Frequentist Probability\nThe frequentist approach to probability depends on the repeatability of some process and the ability to count the number of repetitions, as well as the number of times that some event of interest occurs. The probability describes the long-run relative frequency of occurrences from the process.\n\n\n\n\n\n\n\nFrequentist/A Posteriori Probability\n\n\nProbability is defined as follows: If some process is repeated a large number of times, \\(n\\), and if some resulting event with the characteristic \\(E\\) occurs \\(m\\) times, the relative frequency of occurrence of \\(E\\), \\(m/n\\), will be approximately equal to the probability of \\(E\\).\n\\[\nP(E) = m/n\n\\]\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nNote that \\(m/n\\) is only an estimate of the probability, and that \\(n\\) should be large to have a better estimate of \\(P(E)\\).\nExample: Monty-Hall Problem",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#subjective-probability",
    "href": "lecture3.html#subjective-probability",
    "title": "Introduction to Probability",
    "section": "Subjective Probability",
    "text": "Subjective Probability\nThis view holds that probability measures the confidence that a particular individual has in the truth of a particular proposition.\n\n\n\n\n\n\nNote\n\n\nThe most famous example of subjective probability is Bayesian, which is a mathematically formal method to combine experimental data and expert information in producing probabilities.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#helpful-definitions",
    "href": "lecture3.html#helpful-definitions",
    "title": "Introduction to Probability",
    "section": "Helpful Definitions",
    "text": "Helpful Definitions\n\n\n\n\n\n\n\nSample Space\n\n\nA sample space is a list of all possible outcomes that might be observed.\n\n\n\n\n\n\n\n\n\n\n\nEvent\n\n\nAn event is any collection of outcomes in the sample space.\n\n\n\n\n\n\n\n\n\n\n\nMutually Exclusive\n\n\nIf two events \\(E_i\\) and \\(E_j\\) contain no elements in common, these two events are said to be disjoint or mutually exclusive.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#axioms-of-probability",
    "href": "lecture3.html#axioms-of-probability",
    "title": "Introduction to Probability",
    "section": "Axioms of Probability",
    "text": "Axioms of Probability\nThe properties of probability was mathematically formalized by Russian mathematician A.N. Kolgomorov by defining the following axioms:\n\nFor each event \\(E_i\\), the probability of \\(E_i\\) is non-negative.\nThe sum of the probabilities of the mutually exclusive events is equal to 1.\nConsider any two mutually exclusive events, \\(E_i\\) and \\(E_j\\). The probability of occurrence of either \\(E_i\\) or \\(E_j\\) is equal to the sum of their individual probabilities.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#calculating-marginal-probabilities",
    "href": "lecture3.html#calculating-marginal-probabilities",
    "title": "Introduction to Probability",
    "section": "Calculating Marginal Probabilities",
    "text": "Calculating Marginal Probabilities\nWe can calculate the probability of occurrence for events using the sample point method.\n\n\n\n\n\n\n\nSample Point Method\n\n\nUnder the assumption that every outcome in the sample space is equally likely to occur, the probability that some event \\(E_i\\) occurs is defined as the number of outcomes corresponding to \\(E_i\\) divided by the total number of outcomes in the sample space.\nIn frequency distributions, this corresponds to the relative frequency of a specific outcome.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nProbabilities computed using this method are often referred to as marginal probability. Marginal probabilities are unconditional and are specific to an event.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example",
    "href": "lecture3.html#example",
    "title": "Introduction to Probability",
    "section": "Example",
    "text": "Example\nOut of 1,325 university students, 532 of them reported to consume caffeine through coffee. What is the marginal probability of selecting a university student who consumes coffee?\n\\[\nP(E) = \\frac{532}{1325}\n\\]\nThe resulting probability is 0.402.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example-2",
    "href": "lecture3.html#example-2",
    "title": "Introduction to Probability",
    "section": "Example 2",
    "text": "Example 2\nConsider the AMSSurvey data in the package carData. The data set includes the counts of new PhDs in the mathematical sciences for 2008-09 and 2011-12 categorized by type of institution, gender, and US citizenship status. You can learn more about the data set by typing ?carData::AMSsurvey after installing the car package.\n\nQuestion + DataAnswer\n\n\nWhat is the probability of selecting a participant of the survey at random who is not a US citizen in 2008? Use the count variable.\n\nlibrary(carData)\nAMSsurvey\n\n    type    sex citizen count count11\n1  I(Pu)   Male      US   132     148\n2  I(Pu) Female      US    35      40\n3  I(Pr)   Male      US    87      63\n4  I(Pr) Female      US    20      22\n5     II   Male      US    96     161\n6     II Female      US    47      53\n7    III   Male      US    47      71\n8    III Female      US    32      28\n9     IV   Male      US    71      89\n10    IV Female      US    54      55\n11    Va   Male      US    34      42\n12    Va Female      US    14      21\n13 I(Pu)   Male  Non-US   130     136\n14 I(Pu) Female  Non-US    29      32\n15 I(Pr)   Male  Non-US    79      82\n16 I(Pr) Female  Non-US    25      26\n17    II   Male  Non-US    89     116\n18    II Female  Non-US    50      56\n19   III   Male  Non-US    53      61\n20   III Female  Non-US    39      30\n21    IV   Male  Non-US   122     153\n22    IV Female  Non-US   105     115\n23    Va   Male  Non-US    28      27\n24    Va Female  Non-US    12      17\n\n\n\n\nThe total counts can be calculated using the sum function. Or simple addition.\n\nsum(AMSsurvey$count)\n\n[1] 1430\n\n\nWe can also count the total number of non-US citizens in the data set.\n\n130+29+79+25+89+50+53+39+122+105+28+12\n\n[1] 761\n\n\nThus, the probability can be calculated as 761/ 1430 = 0.532",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#exercise",
    "href": "lecture3.html#exercise",
    "title": "Introduction to Probability",
    "section": "Exercise",
    "text": "Exercise\nThe “COVID-19 Effects on the Mental and Physical Health of Asian Americans & Pacific Islanders Survey Study II” (COMPASS II) data set is from a follow-up survey implemented from 12/2021 to 05/2022. The data set is composed of responses from 3,411 participants. (Do et al. 2025)\n\nExerciseAnswer\n\n\nThe table below shows the breakdown of the census region reported by the participants. What is the probability that a randomly selected participant was from the Northeast census region?\n\n\n\nCensus Region\nFrequency\n\n\n\n\nMidwest\n289\n\n\nNortheast\n344\n\n\nSouth\n472\n\n\nWest\n2,303\n\n\n\n\n\nThe marginal probability is 344/3411 = 0.101",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#union-of-events",
    "href": "lecture3.html#union-of-events",
    "title": "Introduction to Probability",
    "section": "Union of Events",
    "text": "Union of Events\nUnion means “together”: the union of events \\(A\\) and \\(B\\) consists of all outcomes that are either in event A, event B, or both.\n\n\n\n\n\n\nNote\n\n\nThe union of events is mathematically denoted by \\(\\cup\\) or “OR”.\nAs an example, consider Event A: drawing an ace from a standard deck of cards and Event B: drawing a diamond from a standard deck of cards. The union of events A and B can be interpreted as “the event where we draw an ace or a diamond card” or in mathematical terms \\(Ace \\cup Diamond\\).",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#intersection-of-events",
    "href": "lecture3.html#intersection-of-events",
    "title": "Introduction to Probability",
    "section": "Intersection of Events",
    "text": "Intersection of Events\nThe intersection of events \\(A\\) and \\(B\\) consists of all outcomes that are in event A AND event B.\n\n\n\n\n\n\nNote\n\n\nThe intersection of events is mathematically denoted by \\(\\cap\\) or “AND”.\nAs an example, consider Event A: drawing an ace from a standard deck of cards and Event B: drawing a diamond from a standard deck of cards. The intersection of events A and B can be interpreted as “the event where we draw an ace AND a diamond card” or in mathematical terms \\(Ace \\cap Diamond\\). This simplifies to drawing of a specific card: the ace of diamonds.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#union-vs.-intersection",
    "href": "lecture3.html#union-vs.-intersection",
    "title": "Introduction to Probability",
    "section": "Union vs. Intersection",
    "text": "Union vs. Intersection\n\nOr vs. And",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#additive-law-of-probability",
    "href": "lecture3.html#additive-law-of-probability",
    "title": "Introduction to Probability",
    "section": "Additive Law of Probability",
    "text": "Additive Law of Probability\nFor any two events \\(A\\) and \\(B\\), the probability of \\(A\\) or \\(B\\) occurring is equal to:\n\\[\nP(A \\cup B) = P(A)+P(B) - P(A \\cap B)\n\\]\n\n\n\n\n\n\nImportant\n\n\nDisjoint events cannot happen at the same time. For disjoint events \\(C\\) and \\(D\\), \\(P(C \\cap D) = 0\\). Therefore, \\(P(C \\cup D) = P(C)+P(D)\\) is consistent with Axiom 3.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example-1",
    "href": "lecture3.html#example-1",
    "title": "Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhat is the probability of rolling a 1 or 3 on a single roll of a fair six-sided die?\n\n\n\n\n\n\nImportant\n\n\nRolling a 1 and a 3 is not possible. Thus, \\(P(roll 1 \\cap roll 3) = 0\\).\n\n\n\n\\[\nP(roll 1 \\cup roll 3) = P(roll 1) + P(roll 3) - P (roll 1 \\cap roll 3)\n\\] \\[\nP(roll 1 \\cup roll 3) = 1/6+1/6-0 = 1/3\n\\]\nThus, \\(P(roll 1 \\cup roll 3)=\\) 0.3333",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example-2-1",
    "href": "lecture3.html#example-2-1",
    "title": "Introduction to Probability",
    "section": "Example 2",
    "text": "Example 2\nConsider a standard deck of playing cards. What is the probability of drawing an ace or a diamond card?\n\n\n\n\n\n\nImportant\n\n\nDrawing an ace AND a diamond card is possible. This event corresponds to drawing the ace of diamonds. The probability of drawing the ace of diamonds from a standard deck of playing cards is 1/52. Hence, \\(P(A \\cap D) = 1/52\\).\n\n\n\n\\[\nP(A \\cup D) = P(A) + P(D) - P (A \\cap D)\n\\]\n\\[\nP(Ace \\cup Diamond) = 4/52 + 13/52 - 1/52 = 16/52\n\\] Thus, \\(P(Ace \\cup Diamond)\\) = 0.3077",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#exercise-2",
    "href": "lecture3.html#exercise-2",
    "title": "Introduction to Probability",
    "section": "Exercise",
    "text": "Exercise\nFrom a sample of 30 adults, nine reported cannabis use, eight reported cigarette use, and two reported both cigarette and cannabis use.\n\nQuestionAnswer\n\n\nWhat is the probability that a randomly selected adult from the sample reported cannabis or cigarette use?\n\n\n\\(P(Cannabis)=9/30\\), \\(P(Cigarette)=8/30\\), \\(P(Cannabis\\cap Cigarettes) = 2/30\\). Therefore,\n\\[\nP(Cannabis \\cup Cigarettes) = P(Can) + P(Cig) - P(Can\\cap Cig)\n\\]\n\\[\nP(Cannabis \\cup Cigarettes) = 9/30 + 8/30 - 2/30 = 15/30\n\\]\n\\(P(Cannabis \\cup Cigarettes)\\) = 0.5",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#independent-events",
    "href": "lecture3.html#independent-events",
    "title": "Introduction to Probability",
    "section": "Independent Events",
    "text": "Independent Events\nTwo events are independent if knowing the outcome for one of the events provides no information about the outcome of the other event. Mathematically,\n\n\n\n\n\n\n\nIndependent Events\n\n\nTwo events \\(A\\) and \\(B\\) are independent if \\(P(A \\cap B) = P(A)P(B)\\).\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nThe probability \\(P(A \\cap B)\\) is also referred to as the joint probability of \\(A\\) and \\(B\\).",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example-3",
    "href": "lecture3.html#example-3",
    "title": "Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhat is the probability of getting two heads from two independent coin tosses?\n\\[\nP(H1 \\cap H2) = P(H1)P(H2) = (1/2)(1/2)\n\\] \\(P(H1 \\cap H2)\\) = 0.25",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#exercise-3",
    "href": "lecture3.html#exercise-3",
    "title": "Introduction to Probability",
    "section": "Exercise",
    "text": "Exercise\nAccording to the National Down Syndrome Society, the probability that a 35-year-old woman conceives a child with Down syndrome is approximately 0.28%.\n\nExerciseAnswer\n\n\nWhat is the probability that two independently sampled 35-year-old women will both conceive children with Down syndrome?\n\n\n\\[\nP(C1Down \\cap C2Down) = P(C1Down)P(C2Down) = (0.0028)(0.0028)\n\\]\n\\(P(C1Down \\cap C2Down)\\) = 0.000784%",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#complementary-events",
    "href": "lecture3.html#complementary-events",
    "title": "Introduction to Probability",
    "section": "Complementary Events",
    "text": "Complementary Events\nThe complement of an event \\(A\\) is defined to be the set of all elements in the sample space that are NOT A.\n\n\n\n\n\n\nTip\n\n\nThe complement of \\(A\\) is denoted by \\(\\bar{A}\\) or \\(A^C\\).\n\n\n\n\n\n\n\n\n\nNote\n\n\nFor any event \\(A\\) and its complement \\(A^C\\),\n\\[\nP(A^C) = 1-P(A)\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example-4",
    "href": "lecture3.html#example-4",
    "title": "Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhat is the probability of NOT getting a 1 after rolling a fair six-sided die?\n\\[\nP([roll 1]^C) = 1 - P(roll 1) = 1-\\frac{1}{6} = \\frac{5}{6}\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#exercise-5",
    "href": "lecture3.html#exercise-5",
    "title": "Introduction to Probability",
    "section": "Exercise",
    "text": "Exercise\nIn a survey study, 10.7% reported to have taken undergraduate courses, 23.4% reported to have finished an undergraduate (Bachelor’s/Associates) degree, 15.2% reported to have taken postgraduate credits, and 3.9% reported to have finished a graduate degree.\n\nQuestionAnswer\n\n\nWhat is the probability of randomly sampling a participant who had not received any college-level education?\n\n\nEducational attainment are assumed to be disjoint because respondents cannot be in multiple levels. Hence,\n\\[\nP(College) = 0.107+0.234+0.152+0.039\n\\]\nThe complement is what we’re interested in.\n\\[\nP(NoCollege) = 1-(0.107+0.234+0.152+0.039)\n\\]\nThe resulting probability is 0.468",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#conditional-probability",
    "href": "lecture3.html#conditional-probability",
    "title": "Introduction to Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\nIf two events are dependent, then knowing the outcome of one event provides information about the probability of the other event.\n\n\n\n\n\n\nNote\n\n\nIn screening tests, the probability of a positive test depends on whether the subject has the condition or not.\n\n\n\n\n\n\n\n\n\nTip\n\n\nThe notation for conditional probabilities is \\(P(A|B)\\), which is read as the “probability of \\(A\\) given \\(B\\)”.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nConditional probabilities are order-specific, i.e. \\(P(A|B) \\neq P(B|A)\\).",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example-5",
    "href": "lecture3.html#example-5",
    "title": "Introduction to Probability",
    "section": "Example",
    "text": "Example\nConsider the AMSSurvey data in the package carData. The data set includes the counts of new PhDs in the mathematical sciences for 2008-09 and 2011-12 categorized by type of institution, gender, and US citizenship status.\n\nQuestion + DataAnswer\n\n\nWhat is the probability that a randomly selected participant is enrolled in a statistics/biostatistics program(type=IV) in 2008 (count variable) given that they are known to be a US citizen?\n\nlibrary(carData)\nAMSsurvey\n\n    type    sex citizen count count11\n1  I(Pu)   Male      US   132     148\n2  I(Pu) Female      US    35      40\n3  I(Pr)   Male      US    87      63\n4  I(Pr) Female      US    20      22\n5     II   Male      US    96     161\n6     II Female      US    47      53\n7    III   Male      US    47      71\n8    III Female      US    32      28\n9     IV   Male      US    71      89\n10    IV Female      US    54      55\n11    Va   Male      US    34      42\n12    Va Female      US    14      21\n13 I(Pu)   Male  Non-US   130     136\n14 I(Pu) Female  Non-US    29      32\n15 I(Pr)   Male  Non-US    79      82\n16 I(Pr) Female  Non-US    25      26\n17    II   Male  Non-US    89     116\n18    II Female  Non-US    50      56\n19   III   Male  Non-US    53      61\n20   III Female  Non-US    39      30\n21    IV   Male  Non-US   122     153\n22    IV Female  Non-US   105     115\n23    Va   Male  Non-US    28      27\n24    Va Female  Non-US    12      17\n\n\n\n\nIn total, there are 669 US citizens in the data set. Among them, there are 71+54 = 125 enrolled in statistics/biostatistics program (type=IV).\nTherefore, the probability that a participant who is a known US citizen is enrolled in a statistics/biostatistics program is \\(\\frac{71+54}{132+35+87+20+96+47+47+32+71+54+34+14}\\) = 0.186846",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#multiplicative-law-of-probability",
    "href": "lecture3.html#multiplicative-law-of-probability",
    "title": "Introduction to Probability",
    "section": "Multiplicative Law of Probability",
    "text": "Multiplicative Law of Probability\nLet \\(A\\) and \\(B\\) be events, and suppose \\(P(B) \\neq 0\\). Then, the joint, marginal, and conditional probabilities can be related by the following equation.\n\\[\nP(A \\cap B) = P(B) P(A|B)\n\\]\nUsing basic algebra, we can derive an expression for the conditional probability.\n\\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example-6",
    "href": "lecture3.html#example-6",
    "title": "Introduction to Probability",
    "section": "Example",
    "text": "Example\nSuppose the probability of traffic light failure is 0.0002. A local transportation office calculated that when there is a traffic light failure, there is a 20% chance of a vehicular accident occurring. What is the probability of a vehicular accident and a traffic light failure occurring at the same time?\n\n\\(P(Fail) = 0.0002\\)\n\\(P(Acc|Fail) = 0.20\\)\n\n\\[\nP(Acc \\cap Fail) = P(Acc|Fail) P(Fail)\n\\] \\(P(Acc \\cap Fail) = 0.0002 * 0.20\\) = 0.00004",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example-2-2",
    "href": "lecture3.html#example-2-2",
    "title": "Introduction to Probability",
    "section": "Example 2",
    "text": "Example 2\nConsider the AMSSurvey data in the package carData. The data set includes the counts of new PhDs in the mathematical sciences for 2008-09 and 2011-12 categorized by type of institution, gender, and US citizenship status.\n\nQuestion + DataAnswer\n\n\nUse the multiplication rule to calculate the probability that a randomly selected participant is enrolled in a statistics/biostatistics program(type=IV) in 2008 (count variable) given that they are known to be a US citizen.\n\nlibrary(carData)\nAMSsurvey\n\n    type    sex citizen count count11\n1  I(Pu)   Male      US   132     148\n2  I(Pu) Female      US    35      40\n3  I(Pr)   Male      US    87      63\n4  I(Pr) Female      US    20      22\n5     II   Male      US    96     161\n6     II Female      US    47      53\n7    III   Male      US    47      71\n8    III Female      US    32      28\n9     IV   Male      US    71      89\n10    IV Female      US    54      55\n11    Va   Male      US    34      42\n12    Va Female      US    14      21\n13 I(Pu)   Male  Non-US   130     136\n14 I(Pu) Female  Non-US    29      32\n15 I(Pr)   Male  Non-US    79      82\n16 I(Pr) Female  Non-US    25      26\n17    II   Male  Non-US    89     116\n18    II Female  Non-US    50      56\n19   III   Male  Non-US    53      61\n20   III Female  Non-US    39      30\n21    IV   Male  Non-US   122     153\n22    IV Female  Non-US   105     115\n23    Va   Male  Non-US    28      27\n24    Va Female  Non-US    12      17\n\n\n\n\nThe marginal probability of selecting a US citizen is \\(\\frac{669}{669+761}=\\) 0.4678.\nThe probability of selecting a US citizen and type=IV is \\(\\frac{(71+54)}{(669+761)}=\\) 0.0874\nTherefore, the probability of selecting a participant in type=IV given that they are a US citizen is:\n\\[\nP(IV|US) = \\frac{P(IV \\cap US)}{P(US)} = \\frac{\\frac{(71+54)}{(669+761)}}{\\frac{669}{669+761}}\n\\]\nResulting in the following value: 0.1868, which was the same value as in the previous example.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#exercise-6",
    "href": "lecture3.html#exercise-6",
    "title": "Introduction to Probability",
    "section": "Exercise",
    "text": "Exercise\nIn 2016, the global incidence rate of the Zika virus is 0.0017. Suppose a screening test was developed such that the probability of a positive test result given that the participant had the Zika virus is 0.90.\n\nQuestionAnswer\n\n\nWhat is the probability that a randomly selected individual tested positive and had Zika virus?\n\n\n\n\\(P(Z) =0.0017\\)\n\\(P(PT|Z) = 0.90\\)\n\\(P(PT \\cap Z) = P(PT|Z)P(Z) = (0.90)(0.0017)\\) = 0.0015",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#law-of-total-probability",
    "href": "lecture3.html#law-of-total-probability",
    "title": "Introduction to Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\nThe law of probability states that for events \\({B_1,B_2,...,B_n}\\) that are disjoint outcomes that span the sample space, and with \\(P(B_j) \\neq 0\\) for all \\(j\\), then for any event \\(A\\),\n\\[\nP(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + ... = \\sum_{i=1}^n P(A|B_i)P(B_i)\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#bayes-theorem-1",
    "href": "lecture3.html#bayes-theorem-1",
    "title": "Introduction to Probability",
    "section": "Bayes’ Theorem",
    "text": "Bayes’ Theorem\nRecall that \\(P(B|A) \\neq P(A|B)\\). Bayes’ theorem provides a way to invert conditional probabilities.\n\n\n\n\n\n\n\nBayes’ Theorem\n\n\nLet \\(A\\) and \\(B_1, B_2,...,B_n\\) be disjoint events that span the whole sample space, and with \\(P(B_j) \\neq 0\\) for all \\(j\\),\n\\[\nP(B_j|A) = \\frac{P(A|B_j) P(B_j)}{\\sum_{i=1}^n P(A|B_i)P(B_i)}\n\\]\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nIf we know the marginal probability of \\(A\\),\n\\[\nP(B_j|A) = \\frac{P(A|B_j) P(B_j)}{P(A)}\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#screening-tests-1",
    "href": "lecture3.html#screening-tests-1",
    "title": "Introduction to Probability",
    "section": "Screening Tests",
    "text": "Screening Tests\nWhen screening for diseases, we are interested in the true positive (positive tests for people who have the disease) and true negative rates (negative tests for people who do not have the disease).\n\n\n\n\nAN (+)\nAN(-)\n\n\nTest (+)\nTP\nFP\n\n\nTest (-)\nFN\nTN\n\n\n\n\nSensitivitySpecificityBase Rate\n\n\n\n\n\n\n\n\n\nSensitivity\n\n\nThe probability that a person randomly selected from the population tests positive given that they have the disease is called the sensitivity of a test.\n\\[\nSens = P(PT|D) = \\frac{TP}{TP+FN}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecificity\n\n\nThe probability that a person randomly selected from the population tests negative given that they do not have the disease is called the specificity of a test.\n\\[\nSpec = P(NT|ND) = 1-P(PT|ND) =  \\frac{TN}{TN+FP}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nBase Rate\n\n\nThe probability that a person randomly selected from the population has the disease is called the base rate of a test.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#positive-predictive-value",
    "href": "lecture3.html#positive-predictive-value",
    "title": "Introduction to Probability",
    "section": "Positive Predictive Value",
    "text": "Positive Predictive Value\nWe are also interested in the conditional probabilities of having the disease based on the test for a random member of the population.\n\n\n\n\n\n\n\nPositive Predictive Value (PPV)\n\n\nThe probability of having the disease given a positive test (P(D|PT)) is called the positive predictive value (PPV).\n\\[\nP(D|PT) = \\frac{P(PT|D)P(D)}{P(PT)} = \\frac{sens*BR}{sens*BR + (1-spec)*(1-BR)}\n\\]\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nThe positive predictive value can be calculated using a contingency table based on the results of the screening tests, but this might not reflect the true predictive value for a randomly selected member of the population.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#negative-predictive-value",
    "href": "lecture3.html#negative-predictive-value",
    "title": "Introduction to Probability",
    "section": "Negative Predictive Value",
    "text": "Negative Predictive Value\n\n\n\n\n\n\n\nNegative Predictive Value (NPV)\n\n\nThe probability of not having the disease given a negative test (P(ND|NT)) is called the negative predictive value (NPV).\n\\[\nP(ND|NT) = \\frac{P(NT|ND)P(ND)}{P(NT)} = \\frac{spec*(1-BR)}{spec*(1-BR) + (1-sens)*(BR)}\n\\]\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nThe negative predictive value can be calculated using a contingency table based on the results of the screening tests, but this might not reflect the true predictive value for a randomly selected member of the population.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example-7",
    "href": "lecture3.html#example-7",
    "title": "Introduction to Probability",
    "section": "Example",
    "text": "Example\nSuppose a screening test designed for virus X has a sensitivity of 0.64 and a specificity of 0.98.\n\nQuestionAnswer\n\n\nIf the base rate of virus X is 0.002,\n\nWhat is the negative predictive value of the test?\nWhat is the positive predictive value of the test?\n\n\n\n\nNPV\n\n\nsens &lt;- 0.64\nspec &lt;- 0.98\nbr &lt;- 0.002\n\n(spec*(1-br))/(spec*(1-br) + (1-sens)*br)\n\n[1] 0.9992644\n\n\n\nPPV\n\n\n(sens*br)/(sens*br + (1-spec)*(1-br))\n\n[1] 0.06026365\n\n\nA negative test would most likely mean the subject does not have the disease, but a positive test will most likely need other confirmatory tests to confirm if the subject has the disease.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#example-8",
    "href": "lecture3.html#example-8",
    "title": "Introduction to Probability",
    "section": "Example",
    "text": "Example\nSuppose a screening test designed for virus X has a sensitivity of 0.64 and a specificity of 0.98.\n\nQuestionAnswer\n\n\nIf the base rate of virus X is 0.002,\n\nWhat is the negative predictive value of the test?\nWhat is the positive predictive value of the test?\n\n\n\n\nNPV\n\n\nsens &lt;- 0.64\nspec &lt;- 0.98\nbr &lt;- 0.002\n\n(spec*(1-br))/(spec*(1-br) + (1-sens)*br)\n\n[1] 0.9992644\n\n\n\nPPV\n\n\n(sens*br)/(sens*br + (1-spec)*(1-br))\n\n[1] 0.06026365\n\n\nA negative test would most likely mean the subject does not have the disease, but a positive test will most likely need other confirmatory tests to confirm if the subject has the disease.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#exercise-7",
    "href": "lecture3.html#exercise-7",
    "title": "Introduction to Probability",
    "section": "Exercise",
    "text": "Exercise\nConsider a screening instrument developed to detect symptoms of anorexia nervosa in adolescents. The instrument was validated against the Eating Attitudes Test (EAT) results. The results are shown below.\n\n\n\n\nAN (+)\nAN(-)\n\n\nTest (+)\n250\n32\n\n\nTest (-)\n68\n784\n\n\n\n\nQuestionAnswer\n\n\nAssuming the prevalence rate of anorexia nervosa in adolescents is 7%,\n\nWhat is the sensitivity of the test?\nWhat is the specificity of the test?\nWhat is the probability that a randomly screened adolescent has anorexia nervosa given they tested positive?\nWhat is the probability that a randomly screened adolescent does not have anorexia nervosa given they tested negative?\n\n\n\n\nWhat is the sensitivity of the test?\n\n\n250/(250+68)\n\n[1] 0.7861635\n\n\n\nWhat is the specificity of the test?\n\n\n784/(784+32)\n\n[1] 0.9607843\n\n\n\nWhat is the probability that a randomly screened adolescent has anorexia nervosa given they tested positive? \\(\\to\\) PPV\n\n\nsens &lt;- 250/(250+68)\nspec &lt;- 784/(784+32)\nbr &lt;- 0.07\n\n(sens*br)/(sens*br + (1-spec)*(1-br))\n\n[1] 0.6014232\n\n\n\nWhat is the probability that a randomly screened adolescent does not have anorexia nervosa given they tested negative? \\(\\to\\) NPV\n\n\n(spec*(1-br))/(spec*(1-br) + (1-sens)*br)\n\n[1] 0.9835238\n\n\nA positive test has a moderate likelihood that the subject has the disease, and a negative test has a high likelihood that the subject does not have the disease.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#notes-on-screening-tests",
    "href": "lecture3.html#notes-on-screening-tests",
    "title": "Introduction to Probability",
    "section": "Notes on Screening Tests",
    "text": "Notes on Screening Tests\n\n\n\n\n\n\nImportant\n\n\nThere are a lot of available functions in R that calculate sensitivity, specificity, NPV, and PPV. However, you need to be careful about interpreting the PPV and NPV values provided. Sometimes, these values do not account for the base rate.\n\n\n\n\n\n\n\n\n\nTip\n\n\nPackages like yardstick and epiR calculate screening test characteristics and relevant confidence intervals.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture3.html#references",
    "href": "lecture3.html#references",
    "title": "Introduction to Probability",
    "section": "References",
    "text": "References\n\n\n\n\nDo, Vuong Van, Van My Ta Park, Nhung Nguyen, Pamela May Ling, Marian Tzuang, Bora Nam, Marcelle M. Dougan, Oanh L. Meyer, and Janice Y. Tsoh. 2025. “Use of Cigarettes, Cannabis, and Alcohol Among Asian American, Native Hawaiian, and Pacific Islander Adults: Community-Based National Survey Analysis.” JMIR Public Health and Surveillance 11 (1): e76465. https://doi.org/10.2196/76465.",
    "crumbs": [
      "Lectures",
      "Lecture 3- Intro to Probability"
    ]
  },
  {
    "objectID": "lecture1.html#datafication",
    "href": "lecture1.html#datafication",
    "title": "Introduction to Biostatistics and R",
    "section": "Datafication",
    "text": "Datafication\nThe field of statistics has grown in recent years primarily due to the datafication of the world.\n\n\n\n\n\n\nImportant\n\n\n98% of all stored information is digital. Collected data is increasing even at this very moment.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#why-statistics",
    "href": "lecture1.html#why-statistics",
    "title": "Introduction to Biostatistics and R",
    "section": "Why statistics?",
    "text": "Why statistics?\n\n\n\n\n\n\n\nStatistics\n\n\nStatistics is a field of study concerned with:\n\nThe collection, organization, summarization, and analysis of data\nThe drawing of inferences about a body of data when only a part of the data is observed.\n\n\n\n\n\nData \\(\\to\\) Numbers \\(\\to\\) Information \\(\\to\\) Investigation \\(\\to\\) Communication",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#statistical-thinking",
    "href": "lecture1.html#statistical-thinking",
    "title": "Introduction to Biostatistics and R",
    "section": "Statistical Thinking",
    "text": "Statistical Thinking\nHow is statistical thinking different from mathematical thinking?\n\n\n\n\n\n\n\nStatistical Thinking\n\n\nStatistical thinking involves understanding and analyzing data while accounting for uncertainty!",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#activity",
    "href": "lecture1.html#activity",
    "title": "Introduction to Biostatistics and R",
    "section": "Activity",
    "text": "Activity\nFlip a coin 10 times. If you don’t have a coin, search “coin flip” on Google.\n\n\n\n\n\n\nNote\n\n\nHow many times did you get heads? Do you think the coin you flipped was fair?",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#extensions-of-statistics",
    "href": "lecture1.html#extensions-of-statistics",
    "title": "Introduction to Biostatistics and R",
    "section": "Extensions of Statistics",
    "text": "Extensions of Statistics\n\nBiostatisticsData Science\n\n\nBiostatistics involves applying statistical concepts to data from the biological sciences, health sciences, and medicine.\n\n\nData science is the study of how to extract useful information from data using quantitative methods and theories from many fields. The field focuses on large data sets that were not originally designed or collected to address the question of interest.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#sources-of-data",
    "href": "lecture1.html#sources-of-data",
    "title": "Introduction to Biostatistics and R",
    "section": "Sources of Data",
    "text": "Sources of Data\nAvailable data usually come from the following sources:\n\nRecords\nSurveys\nExperiments\nData Banks\nPrior Literature",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#categories-of-statistics",
    "href": "lecture1.html#categories-of-statistics",
    "title": "Introduction to Biostatistics and R",
    "section": "Categories of Statistics",
    "text": "Categories of Statistics\n\nDescriptive StatisticsInferential Statistics\n\n\nDescriptive statistics are used to describe properties of complex sets of numbers. Summary statistics are a good example of descriptive statistics.\n\n\nInferential statistics are used to infer information from a smaller group (sample) to a more general group (population).",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#random-variables",
    "href": "lecture1.html#random-variables",
    "title": "Introduction to Biostatistics and R",
    "section": "Random Variables",
    "text": "Random Variables\nRandom variables have values obtained arise as a result of chance factors, so that they cannot be exactly predicted in advance. Values of random variables resulting from measurement procedures are referred to as observations/measurements.\n\n\n\n\n\n\nNote\n\n\nRandom variables could be classified as qualitative or quantitative.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#random-variable-types",
    "href": "lecture1.html#random-variable-types",
    "title": "Introduction to Biostatistics and R",
    "section": "Random Variable Types",
    "text": "Random Variable Types\n\nQuantitative VariablesQualitative Variables\n\n\nQuantitative variables are variables that can be measured or characterized with a numerical value.\n\n\n\n\n\n\n\nDiscrete Random Variables\n\n\nA discrete variable is characterized by gaps or interruptions in the values that it can assume.\nExample: Customer counts at Cafe Rio, Number of missing teeth, Likert Scale scores\n\n\n\n\n\n\n\n\n\n\n\nContinuous Random Variables\n\n\nA continuous variable is characterized by gaps or interruptions in the values that it can assume.\nExample: Speed, Weight, Time\n\n\n\n\n\n\nQualitative variables cannot be measured numerically, but can be described categorically. Discrete and qualitative variables are also known as categorical variables.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#data-types",
    "href": "lecture1.html#data-types",
    "title": "Introduction to Biostatistics and R",
    "section": "Data Types",
    "text": "Data Types\n\nNominal DataOrdinal DataInterval DataRatio Data\n\n\nAs the name implies, nominal data consist of “naming” observations or classifying them into various mutually exclusive and collectively exhaustive categories.\nExamples: Assigned sex at birth (male,female); HHS Regions (HHS Regions 1-10)\n\n\n\n\n\n\nImportant\n\n\nNominal data are typically qualitative in nature and does not account for any ordering in variable levels.\n\n\n\n\n\nOrdinal data are for variables with values with inherent ordering.\nExamples: Shirt size (Small, Medium, Large, XL); Socioeconomic status (Low, Medium, High)\n\n\n\n\n\n\nImportant\n\n\nOrdinal data can include discrete variables and some qualitative variables.\n\n\n\n\n\nInterval data includes measurements that can be ordered and a distance metric can be defined between two measurements. Interval scales have equal intervals between values with arbitrary zero points.\nExamples: Temperature, IQ\n\n\nRatio data is similar to interval data, but with an absolute zero measurement defined as the “absence” of the variable being measured.\nExamples: Weight, Height",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#exercise",
    "href": "lecture1.html#exercise",
    "title": "Introduction to Biostatistics and R",
    "section": "Exercise",
    "text": "Exercise\n\nQuestionAnswers\n\n\nIdentify the type of data/variable for the following:\n\nBMI\nSatisfaction Scale (Unsatisfied, Moderately Satisfied, Satisfied, Very Satisfied)\nEye Color\nCredit Rating\n\n\n\n\nBMI (ratio)\nSatisfaction Scale (Unsatisfied, Moderately Satisfied, Satisfied, Very Satisfied) (ordinal)\nEye Color (nominal)\nCredit Score (interval)",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#population-vs.-sample",
    "href": "lecture1.html#population-vs.-sample",
    "title": "Introduction to Biostatistics and R",
    "section": "Population vs. Sample",
    "text": "Population vs. Sample\n\n\n\n\n\n\n\nPopulation\n\n\nA population is the largest collection of entities for which we have an interest at a particular time. Measurements of some variable from these entities would generate a population of values for that variable.\nAn exact value calculated from a population is referred to as a parameter.\n\n\n\n\n\n\n\n\n\n\n\nSample\n\n\nA sample is a part of the population.\nAn exact value calculated from a sample is referred to as a statistic.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#population-vs.-sample-1",
    "href": "lecture1.html#population-vs.-sample-1",
    "title": "Introduction to Biostatistics and R",
    "section": "Population vs. Sample",
    "text": "Population vs. Sample\n\n\n\nTaken from: https://medium.com/@ritusantra/population-v-s-sample-f17c40967257",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#how-to-sample",
    "href": "lecture1.html#how-to-sample",
    "title": "Introduction to Biostatistics and R",
    "section": "How to Sample",
    "text": "How to Sample\nSampling can be grouped into two broad categories: probability-based/random sampling and convenience sampling.\n\nRandom SamplesConvenience Samples\n\n\nA sample is a random sample when the probability with which every respondent was sampled is known. These probabilities are not necessarily equal. Types of random sampling include:\n\nSimple random sampling\nStratified random sampling\nCluster sampling\n\n\n\nA sample is a convenience sample when the respondents are selected based on ease of access or availability. This could be a potential source of bias.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#scientific-method",
    "href": "lecture1.html#scientific-method",
    "title": "Introduction to Biostatistics and R",
    "section": "Scientific Method",
    "text": "Scientific Method\nThe scientific method is a process by which scientific information is collected, analyzed, and reported in order to produce unbiased and replicable results in an effort to provide an accurate representation of observable phenomena.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#installation",
    "href": "lecture1.html#installation",
    "title": "Introduction to Biostatistics and R",
    "section": "Installation",
    "text": "Installation\nYou can install R and RStudio on your personal computers and laptops by following the instructions on this page: https://posit.co/download/rstudio-desktop/\nRStudio is currently installed on the classroom computers.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#basic-programming-terminology",
    "href": "lecture1.html#basic-programming-terminology",
    "title": "Introduction to Biostatistics and R",
    "section": "Basic Programming Terminology",
    "text": "Basic Programming Terminology\n\nSource Code: A text listing of commands to be compiled or assembled into an executable computer program.\nRunning Code: The act of telling R to perform an act by giving it commands through source code.\nConsole Pane: Where R commands are entered\n\n\n\n\n\n\n\nImportant\n\n\nThere are different types of programming data types such as integers, doubles/numerics, logicals, and characters.\n\nIntegers (int) have values like -1,0,2\nNumerics (dbl, num) are numbers including integers and decimals,\nLogicals (logi) are either TRUE or FALSE\nCharacters (chr)are text variables such as “Hello, World”, “Female”, “Yes”",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#basic-programming-terminology-1",
    "href": "lecture1.html#basic-programming-terminology-1",
    "title": "Introduction to Biostatistics and R",
    "section": "Basic Programming Terminology",
    "text": "Basic Programming Terminology\n\nVectorsVariablesFactors\n\n\nVectors are a series of values. These can be created using the c() function, known as the combine/concatenate function.\n\nc(1,2,3)\n\n[1] 1 2 3\n\nc(\"A\",\"B\",\"C\")\n\n[1] \"A\" \"B\" \"C\"\n\n\n\n\nYou can store different data types to variables using the &lt;- sign.\n\nvar1 &lt;- c(1,2,3)\nvar1\n\n[1] 1 2 3\n\nvar1+2\n\n[1] 3 4 5\n\nvar2 &lt;- c(\"A\",\"B\",\"C\")\nvar2\n\n[1] \"A\" \"B\" \"C\"\n\n\n\n\nCategorical data are commonly represented in R as factors.\n\nfactor(c(\"18-39\",\"40-59\",\"60+\"), levels=c(\"18-39\",\"40-59\",\"60+\"))\n\n[1] 18-39 40-59 60+  \nLevels: 18-39 40-59 60+\n\nlikert &lt;- c(\"Disagree\", \"Strongly Disagree\",\"Agree\",\"Neutral\",\"Strongly Agree\")\nlikert\n\n[1] \"Disagree\"          \"Strongly Disagree\" \"Agree\"            \n[4] \"Neutral\"           \"Strongly Agree\"   \n\nfactor(likert, levels=c(\"Strongly Disagree\",\"Disagree\", \"Neutral\",\"Agree\",\"Strongly Agree\"))\n\n[1] Disagree          Strongly Disagree Agree             Neutral          \n[5] Strongly Agree   \nLevels: Strongly Disagree Disagree Neutral Agree Strongly Agree",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#basic-programming-technology",
    "href": "lecture1.html#basic-programming-technology",
    "title": "Introduction to Biostatistics and R",
    "section": "Basic Programming Technology",
    "text": "Basic Programming Technology\n\nData FramesConditionalsFunctions\n\n\nData frames are rectangular spreadsheets. Data are typically imported as data frames.\n\n\n\n\n\n\nNote\n\n\nRows correspond to observations and the columns correspond to variables.\n\n\n\nExample:\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\n\n\nYou can test for mathematical relations such as equality/inequality, resulting in a TRUE or FALSE value.\n\n2+1==3\n\n[1] TRUE\n\n3+5 &lt;=1\n\n[1] FALSE\n\nx &lt;- c(1,2,3,4,5)\nx &lt; 3\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\n\n\n\nFunctions are commands in R. c() is a function that combines different values. You can create a function or use functions built for R.\nExample: seq() is a function that generates a sequence of numbers. The resulting sequence of numbers can be changed by changing the attributes of the function\n\nseq(1,5)\n\n[1] 1 2 3 4 5\n\nseq(1,5,by=2)\n\n[1] 1 3 5\n\nseq(1,5,length.out=10)\n\n [1] 1.000000 1.444444 1.888889 2.333333 2.777778 3.222222 3.666667 4.111111\n [9] 4.555556 5.000000\n\n\nTo learn more about what a specific R function does, type ?function_name in the console. (Ex:?seq, ?c)",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#errors-warnings-and-messages",
    "href": "lecture1.html#errors-warnings-and-messages",
    "title": "Introduction to Biostatistics and R",
    "section": "Errors, Warnings, and Messages",
    "text": "Errors, Warnings, and Messages\n\nErrorsWarningsMessages\n\n\nWhen you input a legitimate error, R will warn you using a sentence starting with “Error in” and includes a sentence explaining what went wrong.\n\nadd(1,2,3)\n\nError in add(1, 2, 3): could not find function \"add\"\n\nc(\"A\",\"B\")+1\n\nError in c(\"A\", \"B\") + 1: non-numeric argument to binary operator\n\n\n\n\n\n\n\n\nNote\n\n\nIf the text starts with “Error”, figure out what’s causing it. Think of errors as a red traffic light: stop and assess for anything wrong in the code (missing parenthesis, adding characters to numbers, non-existent functions, etc.)\n\n\n\n\n\n\n\n\n\nImportant\n\n\nEncountering errors in your code is normal even for an experienced coder. Don’t be afraid to review your code if you made an error! This process is called “debuggging”.\n\n\n\n\n\nWhen R produces a warning, your code will still be implemented albeit with some caveats.\n\nfor_plotting &lt;- data.frame(x=c(1,2,3,4,5), y=c(2,4,5,NA,1))\nlibrary(ggplot2)\nggplot(data=for_plotting,aes(x=x,y=y)) + geom_point()\n\n\n\n\n\n\n\n\nThe plot is displayed, but a warning was raised regarding a missing value. Note that the data frame for_plotting has a missing value for y denoted by NA.\n\n\nIf the output text does not start with an error or a warning, it’s just a friendly message from R telling you about the output. These messages are typically seen when loading R packages or data sets from external sources.\n\nlibrary(tidyverse)",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#r-packages",
    "href": "lecture1.html#r-packages",
    "title": "Introduction to Biostatistics and R",
    "section": "R packages",
    "text": "R packages\nR packages extend the functionality of R by providing additional functions, data, and documentation. These packages are written by R users around the world and can be downloaded for free!\n\n\n\n\n\n\nNote\n\n\nThink of R as a new phone. R packages are apps that you can download to use your phone in many different ways.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#installing-and-loading-r-packages",
    "href": "lecture1.html#installing-and-loading-r-packages",
    "title": "Introduction to Biostatistics and R",
    "section": "Installing and Loading R Packages",
    "text": "Installing and Loading R Packages\nLike apps on a phone, R packages also need to be installed. These packages can be installed by running the following code snippet install.packages(\"PackageName\"). For example, to install the package tidyverse used for data manipulation and cleaning, you can run the following code:\ninstall.packages(\"tidyverse\")\nTo load this package in R, you can use the following syntax:\n\nlibrary(tidyverse)\n\n\n\n\n\n\n\nImportant\n\n\nYou must have an active internet connection to install R packages to your device.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#exercise-1",
    "href": "lecture1.html#exercise-1",
    "title": "Introduction to Biostatistics and R",
    "section": "Exercise",
    "text": "Exercise\n\nExerciseAnswer\n\n\nInstall and load the following packages: readxl, nycflights23 and knitr.\n\n\ninstall.packages(\"readxl\")\ninstall.packages(\"nycflights23\")\ninstall.packages(\"knitr\")\n\nlibrary(readxl)\nlibrary(nycflights23)\nlibrary(knitr)",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#exploring-data-sets",
    "href": "lecture1.html#exploring-data-sets",
    "title": "Introduction to Biostatistics and R",
    "section": "Exploring Data Sets",
    "text": "Exploring Data Sets\nThe nycflights23 package includes some data sets saved as data frames. These data sets are related to all domestic flights departing from one of New York City’s three main airports in 2023: Newark Liberty International (EWR), John F. Kennedy International (JFK), and LaGuardia Airport (LGA).\nOne of the data sets in this package is the flights data set.\n\nflights\n\n# A tibble: 435,352 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2023     1     1        1           2038       203      328              3\n 2  2023     1     1       18           2300        78      228            135\n 3  2023     1     1       31           2344        47      500            426\n 4  2023     1     1       33           2140       173      238           2352\n 5  2023     1     1       36           2048       228      223           2252\n 6  2023     1     1      503            500         3      808            815\n 7  2023     1     1      520            510        10      948            949\n 8  2023     1     1      524            530        -6      645            710\n 9  2023     1     1      537            520        17      926            818\n10  2023     1     1      547            545         2      845            852\n# ℹ 435,342 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n\n\n\n\n\nNote\n\n\nA tibble is a special type of data frame! The dimensions show the number of rows x number of columns. Each row corresponds to an observation, while each column corresponds to the variables describing each observation.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#exploring-the-flights-data-set.",
    "href": "lecture1.html#exploring-the-flights-data-set.",
    "title": "Introduction to Biostatistics and R",
    "section": "Exploring the flights data set.",
    "text": "Exploring the flights data set.\nYou can use the following functions to explore a data set.\n\nView()glimpse()kable()$\n\n\nView() brings up RStudio’s built in data viewer. That is, if you want to view data like an Excel sheet.\nView(flights)\n\n\nThe glimpse() function from the package dplyr (part of tidyverse) provides us with a different view of the data set. It includes the data type of each variable defined by the columns of the data frame.\n\nglimpse(flights)\n\nRows: 435,352\nColumns: 19\n$ year           &lt;int&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 1, 18, 31, 33, 36, 503, 520, 524, 537, 547, 549, 551, 5…\n$ sched_dep_time &lt;int&gt; 2038, 2300, 2344, 2140, 2048, 500, 510, 530, 520, 545, …\n$ dep_delay      &lt;dbl&gt; 203, 78, 47, 173, 228, 3, 10, -6, 17, 2, -10, -9, -7, -…\n$ arr_time       &lt;int&gt; 328, 228, 500, 238, 223, 808, 948, 645, 926, 845, 905, …\n$ sched_arr_time &lt;int&gt; 3, 135, 426, 2352, 2252, 815, 949, 710, 818, 852, 901, …\n$ arr_delay      &lt;dbl&gt; 205, 53, 34, 166, 211, -7, -1, -25, 68, -7, 4, -13, -14…\n$ carrier        &lt;chr&gt; \"UA\", \"DL\", \"B6\", \"B6\", \"UA\", \"AA\", \"B6\", \"AA\", \"UA\", \"…\n$ flight         &lt;int&gt; 628, 393, 371, 1053, 219, 499, 996, 981, 206, 225, 800,…\n$ tailnum        &lt;chr&gt; \"N25201\", \"N830DN\", \"N807JB\", \"N265JB\", \"N17730\", \"N925…\n$ origin         &lt;chr&gt; \"EWR\", \"JFK\", \"JFK\", \"JFK\", \"EWR\", \"EWR\", \"JFK\", \"EWR\",…\n$ dest           &lt;chr&gt; \"SMF\", \"ATL\", \"BQN\", \"CHS\", \"DTW\", \"MIA\", \"BQN\", \"ORD\",…\n$ air_time       &lt;dbl&gt; 367, 108, 190, 108, 80, 154, 192, 119, 258, 157, 164, 1…\n$ distance       &lt;dbl&gt; 2500, 760, 1576, 636, 488, 1085, 1576, 719, 1400, 1065,…\n$ hour           &lt;dbl&gt; 20, 23, 23, 21, 20, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6,…\n$ minute         &lt;dbl&gt; 38, 0, 44, 40, 48, 0, 10, 30, 20, 45, 59, 0, 59, 0, 0, …\n$ time_hour      &lt;dttm&gt; 2023-01-01 20:00:00, 2023-01-01 23:00:00, 2023-01-01 2…\n\n\n\n\nThe kable() function is part of the package knitr. In this example, we will use another data set in the nycflights23 package: the airlines data set.\n\nkable(airlines)\n\n\n\n\ncarrier\nname\n\n\n\n\n9E\nEndeavor Air Inc.\n\n\nAA\nAmerican Airlines Inc.\n\n\nAS\nAlaska Airlines Inc.\n\n\nB6\nJetBlue Airways\n\n\nDL\nDelta Air Lines Inc.\n\n\nF9\nFrontier Airlines Inc.\n\n\nG4\nAllegiant Air\n\n\nHA\nHawaiian Airlines Inc.\n\n\nMQ\nEnvoy Air\n\n\nNK\nSpirit Air Lines\n\n\nOO\nSkyWest Airlines Inc.\n\n\nUA\nUnited Air Lines Inc.\n\n\nWN\nSouthwest Airlines Co.\n\n\nYX\nRepublic Airline\n\n\n\n\n\n\n\nThe $ operator allows us to extract and then explore a single variable within a data frame.\n\nairlines$name\n\n [1] \"Endeavor Air Inc.\"      \"American Airlines Inc.\" \"Alaska Airlines Inc.\"  \n [4] \"JetBlue Airways\"        \"Delta Air Lines Inc.\"   \"Frontier Airlines Inc.\"\n [7] \"Allegiant Air\"          \"Hawaiian Airlines Inc.\" \"Envoy Air\"             \n[10] \"Spirit Air Lines\"       \"SkyWest Airlines Inc.\"  \"United Air Lines Inc.\" \n[13] \"Southwest Airlines Co.\" \"Republic Airline\"",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#exercise-3",
    "href": "lecture1.html#exercise-3",
    "title": "Introduction to Biostatistics and R",
    "section": "Exercise",
    "text": "Exercise\n\nExerciseAnswer\n\n\nCan you provide me with two qualitative variables and two quantitative variables in the dataset planes in the nycflights23 package?\n\n\n\nglimpse(planes)\n\nRows: 4,840\nColumns: 9\n$ tailnum      &lt;chr&gt; \"N101DQ\", \"N101DU\", \"N101HQ\", \"N101NN\", \"N102DN\", \"N102DU…\n$ year         &lt;int&gt; 2020, 2018, 2007, 2013, 2020, NA, 2007, 2013, 1998, NA, 2…\n$ type         &lt;chr&gt; \"Fixed wing multi engine\", \"Fixed wing multi engine\", \"Fi…\n$ manufacturer &lt;chr&gt; \"AIRBUS\", \"C SERIES AIRCRAFT LTD PTNRSP\", \"EMBRAER-EMPRES…\n$ model        &lt;chr&gt; \"A321-211\", \"BD-500-1A10\", \"ERJ 170-200 LR\", \"A321-231\", …\n$ engines      &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ seats        &lt;int&gt; 199, 133, 80, 379, 199, 133, 80, 379, 182, 133, 199, 80, …\n$ speed        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ engine       &lt;chr&gt; \"Turbo-fan\", \"Turbo-fan\", \"Turbo-fan\", \"Turbo-fan\", \"Turb…\n\n\nColumns made up of characters are categorical variables. Quantitative variables are those marked as integers.\n\n\n\n\n\n\nImportant\n\n\nNA means that the data point is missing. This is not the same as “NA”, which is a character.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#exercise-5",
    "href": "lecture1.html#exercise-5",
    "title": "Introduction to Biostatistics and R",
    "section": "Exercise",
    "text": "Exercise\n\nExerciseAnswer\n\n\nExplore the data set iris.\n\nHow many observations does iris have?\nHow many variables does iris have?\nUse glimpse() to determine the type of data of each column of iris.\nUse the $ operator to extract the species variable in iris\n\n\n\n\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\niris$Species\n\n  [1] setosa     setosa     setosa     setosa     setosa     setosa    \n  [7] setosa     setosa     setosa     setosa     setosa     setosa    \n [13] setosa     setosa     setosa     setosa     setosa     setosa    \n [19] setosa     setosa     setosa     setosa     setosa     setosa    \n [25] setosa     setosa     setosa     setosa     setosa     setosa    \n [31] setosa     setosa     setosa     setosa     setosa     setosa    \n [37] setosa     setosa     setosa     setosa     setosa     setosa    \n [43] setosa     setosa     setosa     setosa     setosa     setosa    \n [49] setosa     setosa     versicolor versicolor versicolor versicolor\n [55] versicolor versicolor versicolor versicolor versicolor versicolor\n [61] versicolor versicolor versicolor versicolor versicolor versicolor\n [67] versicolor versicolor versicolor versicolor versicolor versicolor\n [73] versicolor versicolor versicolor versicolor versicolor versicolor\n [79] versicolor versicolor versicolor versicolor versicolor versicolor\n [85] versicolor versicolor versicolor versicolor versicolor versicolor\n [91] versicolor versicolor versicolor versicolor versicolor versicolor\n [97] versicolor versicolor versicolor versicolor virginica  virginica \n[103] virginica  virginica  virginica  virginica  virginica  virginica \n[109] virginica  virginica  virginica  virginica  virginica  virginica \n[115] virginica  virginica  virginica  virginica  virginica  virginica \n[121] virginica  virginica  virginica  virginica  virginica  virginica \n[127] virginica  virginica  virginica  virginica  virginica  virginica \n[133] virginica  virginica  virginica  virginica  virginica  virginica \n[139] virginica  virginica  virginica  virginica  virginica  virginica \n[145] virginica  virginica  virginica  virginica  virginica  virginica \nLevels: setosa versicolor virginica\n\n\niris has 150 observations and 5 variables: Sepal Length, Sepal Width, Petal Length, Petal Width, and Species. Species is a factor, while all the other variables are numeric (dbl) in nature.",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#summary-1",
    "href": "lecture1.html#summary-1",
    "title": "Introduction to Biostatistics and R",
    "section": "Summary",
    "text": "Summary\n\nIntroduced biostatistics and its importance\nIntroduced R\nExplored data sets",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "lecture1.html#whats-next",
    "href": "lecture1.html#whats-next",
    "title": "Introduction to Biostatistics and R",
    "section": "What’s next?",
    "text": "What’s next?\nWe will be using R to work with data and perform statistical analysis. We will also explore how to use R to explore and describe data from external sources (.csv files).",
    "crumbs": [
      "Lectures",
      "Lecture 1- Intro to Biostatistics and R"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EAB 703-1002: Biostatistical Methods for the Health Sciences",
    "section": "",
    "text": "This website provides the slides and problem set keys for EAB 703-1002 for Dr. Miguel Fudolig. Content is mainly based on the following books:\n\nDaniel, W. W., & Cross, C. L. (2018). Biostatistics: a foundation for analysis in the health sciences. John Wiley & Sons.\nRigdon, S. E., Fricker Jr, R. D., & Montgomery, D. C. (2024). Introduction to Probability and Statistics for Data Science: with R. Cambridge University Press.\nIsmay, C., Kim, A.Y., & Valdivia, A. (2025). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (2nd ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9781032724546",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "lecture2.html#data-exploration",
    "href": "lecture2.html#data-exploration",
    "title": "Descriptive Statistics",
    "section": "Data Exploration",
    "text": "Data Exploration\nIn order to explore the underlying nature of the provided information, we need to explore the data. This exploration is made much easier if the data are organized and summarized.\n\n\n\n\n\n\n\nRaw Data\n\n\nRaw data are measurements that have not been organized, summarized, or otherwise manipulated. As a biostatistician, it is common to be provided the raw data for any analysis.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#ordered-lists",
    "href": "lecture2.html#ordered-lists",
    "title": "Descriptive Statistics",
    "section": "Ordered Lists",
    "text": "Ordered Lists\nThe easiest step in organizing data is simply to order the data.\n\n\n\n\n\n\n\nOrdered Lists/Arrays\n\n\nAn ordered list is a list of values that are arranged from the smallest to largest value (or largest to smallest).",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#ordered-lists-in-r",
    "href": "lecture2.html#ordered-lists-in-r",
    "title": "Descriptive Statistics",
    "section": "Ordered Lists in R",
    "text": "Ordered Lists in R\nThere are different ways to create an ordered list in R. Let us use the iris dataset in R and the tidyverse() package.\n\nlibrary(tidyverse)\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\n\nsort()arrange()\n\n\nsort(vector) can arrange a vector in ascending or descending order. This works for both numeric and character vectors.\n\nsort(iris$Sepal.Length)\n\n  [1] 4.3 4.4 4.4 4.4 4.5 4.6 4.6 4.6 4.6 4.7 4.7 4.8 4.8 4.8 4.8 4.8 4.9 4.9\n [19] 4.9 4.9 4.9 4.9 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.1 5.1 5.1 5.1\n [37] 5.1 5.1 5.1 5.1 5.1 5.2 5.2 5.2 5.2 5.3 5.4 5.4 5.4 5.4 5.4 5.4 5.5 5.5\n [55] 5.5 5.5 5.5 5.5 5.5 5.6 5.6 5.6 5.6 5.6 5.6 5.7 5.7 5.7 5.7 5.7 5.7 5.7\n [73] 5.7 5.8 5.8 5.8 5.8 5.8 5.8 5.8 5.9 5.9 5.9 6.0 6.0 6.0 6.0 6.0 6.0 6.1\n [91] 6.1 6.1 6.1 6.1 6.1 6.2 6.2 6.2 6.2 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.3\n[109] 6.4 6.4 6.4 6.4 6.4 6.4 6.4 6.5 6.5 6.5 6.5 6.5 6.6 6.6 6.7 6.7 6.7 6.7\n[127] 6.7 6.7 6.7 6.7 6.8 6.8 6.8 6.9 6.9 6.9 6.9 7.0 7.1 7.2 7.2 7.2 7.3 7.4\n[145] 7.6 7.7 7.7 7.7 7.7 7.9\n\nsort(iris$Sepal.Length,decreasing = TRUE)\n\n  [1] 7.9 7.7 7.7 7.7 7.7 7.6 7.4 7.3 7.2 7.2 7.2 7.1 7.0 6.9 6.9 6.9 6.9 6.8\n [19] 6.8 6.8 6.7 6.7 6.7 6.7 6.7 6.7 6.7 6.7 6.6 6.6 6.5 6.5 6.5 6.5 6.5 6.4\n [37] 6.4 6.4 6.4 6.4 6.4 6.4 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.2 6.2 6.2\n [55] 6.2 6.1 6.1 6.1 6.1 6.1 6.1 6.0 6.0 6.0 6.0 6.0 6.0 5.9 5.9 5.9 5.8 5.8\n [73] 5.8 5.8 5.8 5.8 5.8 5.7 5.7 5.7 5.7 5.7 5.7 5.7 5.7 5.6 5.6 5.6 5.6 5.6\n [91] 5.6 5.5 5.5 5.5 5.5 5.5 5.5 5.5 5.4 5.4 5.4 5.4 5.4 5.4 5.3 5.2 5.2 5.2\n[109] 5.2 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0\n[127] 5.0 5.0 4.9 4.9 4.9 4.9 4.9 4.9 4.8 4.8 4.8 4.8 4.8 4.7 4.7 4.6 4.6 4.6\n[145] 4.6 4.5 4.4 4.4 4.4 4.3\n\n\n\n\narrange(dataframe,variable) can sort a column in a data frame. This function is from the dplyr package, which is a part of tidyverse.\n\ndf &lt;- arrange(iris,Sepal.Length)\nglimpse(df)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 4.3, 4.4, 4.4, 4.4, 4.5, 4.6, 4.6, 4.6, 4.6, 4.7, 4.7, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.0, 2.9, 3.0, 3.2, 2.3, 3.1, 3.4, 3.6, 3.2, 3.2, 3.2, 3.…\n$ Petal.Length &lt;dbl&gt; 1.1, 1.4, 1.3, 1.3, 1.3, 1.5, 1.4, 1.0, 1.4, 1.3, 1.6, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.1, 0.2, 0.2, 0.2, 0.3, 0.2, 0.3, 0.2, 0.2, 0.2, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\ndf$Sepal.Length\n\n  [1] 4.3 4.4 4.4 4.4 4.5 4.6 4.6 4.6 4.6 4.7 4.7 4.8 4.8 4.8 4.8 4.8 4.9 4.9\n [19] 4.9 4.9 4.9 4.9 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.1 5.1 5.1 5.1\n [37] 5.1 5.1 5.1 5.1 5.1 5.2 5.2 5.2 5.2 5.3 5.4 5.4 5.4 5.4 5.4 5.4 5.5 5.5\n [55] 5.5 5.5 5.5 5.5 5.5 5.6 5.6 5.6 5.6 5.6 5.6 5.7 5.7 5.7 5.7 5.7 5.7 5.7\n [73] 5.7 5.8 5.8 5.8 5.8 5.8 5.8 5.8 5.9 5.9 5.9 6.0 6.0 6.0 6.0 6.0 6.0 6.1\n [91] 6.1 6.1 6.1 6.1 6.1 6.2 6.2 6.2 6.2 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.3\n[109] 6.4 6.4 6.4 6.4 6.4 6.4 6.4 6.5 6.5 6.5 6.5 6.5 6.6 6.6 6.7 6.7 6.7 6.7\n[127] 6.7 6.7 6.7 6.7 6.8 6.8 6.8 6.9 6.9 6.9 6.9 7.0 7.1 7.2 7.2 7.2 7.3 7.4\n[145] 7.6 7.7 7.7 7.7 7.7 7.9\n\n\n\ndf &lt;- arrange(iris,desc(Sepal.Length))\nglimpse(df)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 7.9, 7.7, 7.7, 7.7, 7.7, 7.6, 7.4, 7.3, 7.2, 7.2, 7.2, 7.…\n$ Sepal.Width  &lt;dbl&gt; 3.8, 3.8, 2.6, 2.8, 3.0, 3.0, 2.8, 2.9, 3.6, 3.2, 3.0, 3.…\n$ Petal.Length &lt;dbl&gt; 6.4, 6.7, 6.9, 6.7, 6.1, 6.6, 6.1, 6.3, 6.1, 6.0, 5.8, 5.…\n$ Petal.Width  &lt;dbl&gt; 2.0, 2.2, 2.3, 2.0, 2.3, 2.1, 1.9, 1.8, 2.5, 1.8, 1.6, 2.…\n$ Species      &lt;fct&gt; virginica, virginica, virginica, virginica, virginica, vi…\n\ndf$Sepal.Length\n\n  [1] 7.9 7.7 7.7 7.7 7.7 7.6 7.4 7.3 7.2 7.2 7.2 7.1 7.0 6.9 6.9 6.9 6.9 6.8\n [19] 6.8 6.8 6.7 6.7 6.7 6.7 6.7 6.7 6.7 6.7 6.6 6.6 6.5 6.5 6.5 6.5 6.5 6.4\n [37] 6.4 6.4 6.4 6.4 6.4 6.4 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.2 6.2 6.2\n [55] 6.2 6.1 6.1 6.1 6.1 6.1 6.1 6.0 6.0 6.0 6.0 6.0 6.0 5.9 5.9 5.9 5.8 5.8\n [73] 5.8 5.8 5.8 5.8 5.8 5.7 5.7 5.7 5.7 5.7 5.7 5.7 5.7 5.6 5.6 5.6 5.6 5.6\n [91] 5.6 5.5 5.5 5.5 5.5 5.5 5.5 5.5 5.4 5.4 5.4 5.4 5.4 5.4 5.3 5.2 5.2 5.2\n[109] 5.2 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0\n[127] 5.0 5.0 4.9 4.9 4.9 4.9 4.9 4.9 4.8 4.8 4.8 4.8 4.8 4.7 4.7 4.6 4.6 4.6\n[145] 4.6 4.5 4.4 4.4 4.4 4.3",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#ordered-lists-pros-and-cons",
    "href": "lecture2.html#ordered-lists-pros-and-cons",
    "title": "Descriptive Statistics",
    "section": "Ordered Lists: Pros and Cons",
    "text": "Ordered Lists: Pros and Cons\nThe ordered list makes it easier to see the data sorted by a specific variable. However, it may be impractical to use for large data sets.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#exercise",
    "href": "lecture2.html#exercise",
    "title": "Descriptive Statistics",
    "section": "Exercise",
    "text": "Exercise\nThe data set USArrests contains statistics, in arrests per 100,000 residents for assault, murder, and rape in each of the 50 US states in 1973.\n\nExerciseAnswer\n\n\nCreate an ordered list for the Assault variable in USArrests. Which state had the highest rate for assault per 100,000 residents?\n\n\n\nsort(USArrests$Assault,decreasing = T)\n\n [1] 337 335 300 294 285 279 276 263 259 255 254 252 249 249 238 236 211 204 201\n[20] 190 188 178 174 161 159 159 156 151 149 145 120 120 120 115 113 110 109 109\n[39] 106 102  86  83  81  72  57  56  53  48  46  45\n\narrange(USArrests,desc(Assault))\n\n               Murder Assault UrbanPop Rape\nNorth Carolina   13.0     337       45 16.1\nFlorida          15.4     335       80 31.9\nMaryland         11.3     300       67 27.8\nArizona           8.1     294       80 31.0\nNew Mexico       11.4     285       70 32.1\nSouth Carolina   14.4     279       48 22.5\nCalifornia        9.0     276       91 40.6\nAlaska           10.0     263       48 44.5\nMississippi      16.1     259       44 17.1\nMichigan         12.1     255       74 35.1\nNew York         11.1     254       86 26.1\nNevada           12.2     252       81 46.0\nIllinois         10.4     249       83 24.0\nLouisiana        15.4     249       66 22.2\nDelaware          5.9     238       72 15.8\nAlabama          13.2     236       58 21.2\nGeorgia          17.4     211       60 25.8\nColorado          7.9     204       78 38.7\nTexas            12.7     201       80 25.5\nArkansas          8.8     190       50 19.5\nTennessee        13.2     188       59 26.9\nMissouri          9.0     178       70 28.2\nRhode Island      3.4     174       87  8.3\nWyoming           6.8     161       60 15.6\nNew Jersey        7.4     159       89 18.8\nOregon            4.9     159       67 29.3\nVirginia          8.5     156       63 20.7\nOklahoma          6.6     151       68 20.0\nMassachusetts     4.4     149       85 16.3\nWashington        4.0     145       73 26.2\nIdaho             2.6     120       54 14.2\nOhio              7.3     120       75 21.4\nUtah              3.2     120       80 22.9\nKansas            6.0     115       66 18.0\nIndiana           7.2     113       65 21.0\nConnecticut       3.3     110       77 11.1\nKentucky          9.7     109       52 16.3\nMontana           6.0     109       53 16.4\nPennsylvania      6.3     106       72 14.9\nNebraska          4.3     102       62 16.5\nSouth Dakota      3.8      86       45 12.8\nMaine             2.1      83       51  7.8\nWest Virginia     5.7      81       39  9.3\nMinnesota         2.7      72       66 14.9\nNew Hampshire     2.1      57       56  9.5\nIowa              2.2      56       57 11.3\nWisconsin         2.6      53       66 10.8\nVermont           2.2      48       32 11.2\nHawaii            5.3      46       83 20.2\nNorth Dakota      0.8      45       44  7.3\n\n\nNorth Carolina had the highest rate of Assault arrests per 100,000 residents with 337.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#frequency-tables-categorical-variables",
    "href": "lecture2.html#frequency-tables-categorical-variables",
    "title": "Descriptive Statistics",
    "section": "Frequency Tables: Categorical Variables",
    "text": "Frequency Tables: Categorical Variables\nOne way to summarize a data set is through frequency tables, which counts the frequency of occurrence of values in the data set. To group a set of observations, we select a set of contiguous, nonoverlapping intervals such that each value in the set of observations can be placed in one, and only one, of the intervals.\n\n\n\n\n\n\nNote\n\n\nFor categorical variables, these intervals can be defined by the categories in the variable.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nFrequency tables are also referred to as frequency distributions.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#frequency-tables-categorical-variables-1",
    "href": "lecture2.html#frequency-tables-categorical-variables-1",
    "title": "Descriptive Statistics",
    "section": "Frequency Tables: Categorical Variables",
    "text": "Frequency Tables: Categorical Variables\nHere is an example of a frequency table. The data set flights in the nycflights23 package includes data for all flights that departed from airports in New York city. Recall that this data set has 435,452 rows. If we wished to determine where most flights originated from (column origin), we can count the number of rows that mentioned each of the airports.\nTo create a basic frequency table, we can use the function count(dataframe,variable) in the dplyr package.\n\nlibrary(nycflights23)\ncount(flights,origin)\n\n# A tibble: 3 × 2\n  origin      n\n  &lt;chr&gt;   &lt;int&gt;\n1 EWR    138578\n2 JFK    133048\n3 LGA    163726",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#exercise-2",
    "href": "lecture2.html#exercise-2",
    "title": "Descriptive Statistics",
    "section": "Exercise",
    "text": "Exercise\nFor the following exercise, use the infert data set, which has data on education level, age, parity (previous pregnancies), and the incidence of infertility after spontaneous and induced abortion.\n\nExerciseAnswer\n\n\nAfter examining the data set using glimpse, create a frequency table for the education level of the subjects given by the variable education.\n\n\n\ncount(infert,education)\n\n  education   n\n1    0-5yrs  12\n2   6-11yrs 120\n3   12+ yrs 116",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#relative-frequency",
    "href": "lecture2.html#relative-frequency",
    "title": "Descriptive Statistics",
    "section": "Relative Frequency",
    "text": "Relative Frequency\nIt may be useful at times to know the proportion, rather than the number, of values falling within a particular class interval. We obtain this information by dividing the number of values in the particular class interval by the total number of values. For an interval with \\(k\\) occurrences out of a total of \\(N\\) events, the relative frequency can be calculated by:\n\\[\nRel. Freq. = n/N\n\\]\n\n\n\n\n\n\nNote\n\n\nThe relative frequency can be reported as a decimal or as a percentage (\\(\\times 100\\%\\)).",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#cumulative-relative-frequency",
    "href": "lecture2.html#cumulative-relative-frequency",
    "title": "Descriptive Statistics",
    "section": "Cumulative Relative Frequency",
    "text": "Cumulative Relative Frequency\nWe may sum, or cumulate, the relative frequencies to facilitate obtaining information regarding the relative frequency of values within two or more contiguous class intervals.\n\n\n\n\n\n\nNote\n\n\nThe sum of relative frequencies is referred to as the cumulative relative frequency",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#calculating-relative-and-cumulative-frequencies",
    "href": "lecture2.html#calculating-relative-and-cumulative-frequencies",
    "title": "Descriptive Statistics",
    "section": "Calculating Relative and Cumulative Frequencies",
    "text": "Calculating Relative and Cumulative Frequencies\nLet’s try to calculate these frequencies by hand using the origin frequency distribution example from nycflights.\n\n\n\n\n\n\n\n\norigin\nn\n\n\n\n\nEWR\n138578\n\n\nJFK\n133048\n\n\nLGA\n163726\n\n\n\n\n\n\n\n\nRelative Freq.Cumulative Freq.Cumulative Rel. Freq.\n\n\nFor EWR: \\(\\frac{138578}{(138578 + 133048 + 163726)}=\\) 0.3183125\nFor JFK: \\(\\frac{133048}{(138578 + 133048 + 163726)}=\\) 0.3056102\nFor LGA: \\(\\frac{163726}{(138578 + 133048 + 163726)}=\\) 0.3760773\n\n\nFor EWR: 138578\nFor EWR + JFK: \\(138578+133048=\\) 271626\nFor EWR+JFK + LGA: \\((138578 + 133048 + 163726)=\\) 435352\n\n\nFor EWR: \\(\\frac{138578}{(138578 + 133048 + 163726)}=\\) 0.3183125\nFor EWR + JFK: \\(\\frac{138578+133048}{(138578 + 133048 + 163726)}=\\) 0.6239227\nFor EWR+JFK + LGA: \\(\\frac{133048+138578 + 163726}{(138578 + 133048 + 163726)}=\\) 1",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#frequency-tables-in-r",
    "href": "lecture2.html#frequency-tables-in-r",
    "title": "Descriptive Statistics",
    "section": "Frequency Tables in R",
    "text": "Frequency Tables in R\nThere are a lot of ways to create frequency tables in R. One of the easiest and most complete ways is to use the function freq in the package summarytools.\n\n# install.packages(\"summarytools\") # if you have not installed summarytools yet.\n\nlibrary(summarytools)\nfreq(flights$origin)\n\nFrequencies  \nflights$origin  \nType: Character  \n\n                Freq   % Valid   % Valid Cum.   % Total   % Total Cum.\n----------- -------- --------- -------------- --------- --------------\n        EWR   138578     31.83          31.83     31.83          31.83\n        JFK   133048     30.56          62.39     30.56          62.39\n        LGA   163726     37.61         100.00     37.61         100.00\n       &lt;NA&gt;        0                               0.00         100.00\n      Total   435352    100.00         100.00    100.00         100.00\n\n\n\n\n\n\n\n\nImportant\n\n\nThe &lt;NA&gt; row also counts rows that have missing values. The %Valid column only counts non-missing data, while the % Total column counts missing data in calculating relative and cumulative frequencies. In this example, there are no missing rows, hence the columns are the same.\nThe function also does not output cumulative frequencies, but usually cumulative relative frequencies suffice.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#frequency-tables-quantitative-variables",
    "href": "lecture2.html#frequency-tables-quantitative-variables",
    "title": "Descriptive Statistics",
    "section": "Frequency Tables: Quantitative Variables",
    "text": "Frequency Tables: Quantitative Variables\nThese intervals are usually referred to as class intervals.\n\n\n\n\n\n\nImportant\n\n\nToo few intervals are undesirable because of the resulting loss of information. On the other hand, if too many intervals are used, the objective of summarization will not be met.\nA commonly followed rule of thumb states that there should be no fewer than 5 intervals and no more than 15. However, if the number of intervals fall outside this range, it should be based on theoretical/foundational concepts that could justify the choice of intervals.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#frequency-tables-in-r-qv",
    "href": "lecture2.html#frequency-tables-in-r-qv",
    "title": "Descriptive Statistics",
    "section": "Frequency Tables in R: QV",
    "text": "Frequency Tables in R: QV\nLike categorical variables, there are a lot of ways to create a frequency tables for quantitative variables. However, using freq() directly on a quantitative variable could lead to trivial frequency tables.\n\n\n\n\n\n\nWarning\n\n\nWhat happens if you run the following code?\nfreq(iris$Sepal.Length)",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#frequency-tables-in-r-hist",
    "href": "lecture2.html#frequency-tables-in-r-hist",
    "title": "Descriptive Statistics",
    "section": "Frequency Tables in R: hist()",
    "text": "Frequency Tables in R: hist()\nhist(vector)\nThe function hist() creates both a histogram or a vector of frequencies. To show the vector of frequencies, the plotting mechanism must be turned off. This can be done by setting plot=F. For example,\n\nhist(iris$Sepal.Length,plot=F)\n\n$breaks\n[1] 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 8.0\n\n$counts\n[1]  5 27 27 30 31 18  6  6\n\n$density\n[1] 0.06666667 0.36000000 0.36000000 0.40000000 0.41333333 0.24000000 0.08000000\n[8] 0.08000000\n\n$mids\n[1] 4.25 4.75 5.25 5.75 6.25 6.75 7.25 7.75\n\n$xname\n[1] \"iris$Sepal.Length\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n\n\n\n\n\n\n\nNote\n\n\nIn this output:\n\nBreaks are the endpoints of the intervals used to create the frequency table.\ncounts are the frequencies for each interval.\nmids are the midpoints of each interval, which is commonly used as the representative numbers of each interval.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#frequency-tables-in-rcutvectorbreaks-and-freqvector",
    "href": "lecture2.html#frequency-tables-in-rcutvectorbreaks-and-freqvector",
    "title": "Descriptive Statistics",
    "section": "Frequency Tables in R:cut(vector,breaks) and freq(vector)",
    "text": "Frequency Tables in R:cut(vector,breaks) and freq(vector)\ncut() creates a factor including the intervals for the quantitative variable based on the breaks you provide it. You can provide the breaks using the seq() function or the c() function.\n\n# We must first create a vector of intervals for our frequency table.\n1ranges &lt;- cut(iris$Sepal.Length,breaks=seq(from=4,to=8,by=0.5))\n2head(ranges)\n\n\n1\n\nseq(from=4,to=8,by=0.5) provides a vector of numbers from 4 to 8 in increments of 0.5.\n\n2\n\nThe “(x,y]” notation in the output means that the interval includes y, but not x. The head() function only shows the first 6 elements of ranges.\n\n\n\n\n[1] (5,5.5] (4.5,5] (4.5,5] (4.5,5] (4.5,5] (5,5.5]\nLevels: (4,4.5] (4.5,5] (5,5.5] (5.5,6] (6,6.5] (6.5,7] (7,7.5] (7.5,8]\n\n\nWe can now make a frequency table out of the intervals provided by cut().\n\nfreq(ranges)\n\nFrequencies  \nranges  \nType: Factor  \n\n                Freq   % Valid   % Valid Cum.   % Total   % Total Cum.\n------------- ------ --------- -------------- --------- --------------\n      (4,4.5]      5      3.33           3.33      3.33           3.33\n      (4.5,5]     27     18.00          21.33     18.00          21.33\n      (5,5.5]     27     18.00          39.33     18.00          39.33\n      (5.5,6]     30     20.00          59.33     20.00          59.33\n      (6,6.5]     31     20.67          80.00     20.67          80.00\n      (6.5,7]     18     12.00          92.00     12.00          92.00\n      (7,7.5]      6      4.00          96.00      4.00          96.00\n      (7.5,8]      6      4.00         100.00      4.00         100.00\n         &lt;NA&gt;      0                               0.00         100.00\n        Total    150    100.00         100.00    100.00         100.00",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#exercise-4",
    "href": "lecture2.html#exercise-4",
    "title": "Descriptive Statistics",
    "section": "Exercise",
    "text": "Exercise\nUse the infert data set, which has data on education level, age, parity (previous pregnancies), and the incidence of infertility after spontaneous and induced abortion.\n\nExerciseAnswer\n\n\nCreate a frequency distribution table with relative and cumulative relative frequencies for the education level of the subjects given by the variable education.\n\n\n\nfreq(infert$education)\n\nFrequencies  \ninfert$education  \nType: Factor  \n\n                Freq   % Valid   % Valid Cum.   % Total   % Total Cum.\n------------- ------ --------- -------------- --------- --------------\n       0-5yrs     12      4.84           4.84      4.84           4.84\n      6-11yrs    120     48.39          53.23     48.39          53.23\n      12+ yrs    116     46.77         100.00     46.77         100.00\n         &lt;NA&gt;      0                               0.00         100.00\n        Total    248    100.00         100.00    100.00         100.00",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#descriptive-measures",
    "href": "lecture2.html#descriptive-measures",
    "title": "Descriptive Statistics",
    "section": "Descriptive Measures",
    "text": "Descriptive Measures\nAlthough frequency distributions serve useful purposes, there are many situations that require other types of data summarization. What we need in many instances is the ability to summarize the data by means of a single number called a descriptive measure. Descriptive measures may be computed from the data of a sample or the data of a population.\n\n\n\n\n\n\n\nStatistic vs. Parameter\n\n\nStatistics are descriptive measures computed from a sample. Statistics are typically represented by standard alphabet symbols (\\(\\bar{x},p,r\\)).\nParameters are descriptive measures computed from a population. Parameters are typically represented by Greek letters (\\(\\mu,\\pi,\\rho\\)).",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#measures-of-central-tendency-1",
    "href": "lecture2.html#measures-of-central-tendency-1",
    "title": "Descriptive Statistics",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nMeasures of central tendency provides information on where the central point of the data is. The most common measures of central tendency are:\n\nMean\nMedian\nMode",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#mean",
    "href": "lecture2.html#mean",
    "title": "Descriptive Statistics",
    "section": "Mean",
    "text": "Mean\nThe mean, specifically the arithmetic mean, is the most familiar measure of central tendency.\n\nPopulation MeanSample Mean\n\n\n\n\n\n\n\n\n\nPopulation Mean\n\n\nThe population mean is calculated by adding all the values in the population and dividing by the population size \\(N\\). Formally, for a vector of values given by \\((X_1,X_2,X_3,..., X_N)\\) defining the population, the mean \\(\\mu\\) can be calculated using the following equation:\n\\[\n\\mu = \\frac{(X_1+X_2+X_3+...+X_N)}{N} = \\frac{\\sum_{i=1}^N X_i}{N}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Mean\n\n\nThe sample mean is calculated by adding all the values in the sample and dividing by the sample size \\(k\\). Formally, for a vector of values given by \\((X_1,X_2,X_3,..., X_k)\\) defining the population, the mean \\(\\bar{x}\\) can be calculated using the following equation:\n\\[\n\\bar{x} = \\frac{(X_1+X_2+X_3+...+X_k)}{k} = \\frac{\\sum_{i=1}^k X_i}{k}\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#mean-example",
    "href": "lecture2.html#mean-example",
    "title": "Descriptive Statistics",
    "section": "Mean: Example",
    "text": "Mean: Example\nWhat is the mean of the following numbers: 5, 27, 26, 30, 31?\n\nMath MethodR method\n\n\nThe mean can be calculated using the formula \\((5+27+26+30+31)/5=\\) 23.8\n\n\nThe function mean() outputs the mean of a vector of numbers. Remember to always put the numbers inside the c() function to form a vector.\n\nmean(c(5,27,26,30,31))\n\n[1] 23.8",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#mean-example-1",
    "href": "lecture2.html#mean-example-1",
    "title": "Descriptive Statistics",
    "section": "Mean: Example",
    "text": "Mean: Example\nThe function mean() can also be used to calculate means of quantitative variables in data frames.\n\nmean(iris$Sepal.Length)\n\n[1] 5.843333",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#mean-exercise",
    "href": "lecture2.html#mean-exercise",
    "title": "Descriptive Statistics",
    "section": "Mean: Exercise",
    "text": "Mean: Exercise\nThe data set cars include the speed (speed,in mph) and stopping distance (dist,in ft) of 50 cars recorded in the 1920s.\n\nExerciseAnswer\n\n\nFind the mean stopping distance for these 50 cars.\n\n\n\nmean(cars$dist)\n\n[1] 42.98\n\n\nThe mean stopping distance is 42.98 ft.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#mean-advantages-and-disadvantages",
    "href": "lecture2.html#mean-advantages-and-disadvantages",
    "title": "Descriptive Statistics",
    "section": "Mean: Advantages and Disadvantages",
    "text": "Mean: Advantages and Disadvantages\n\n\n\n\n\n\n\nAdvantages\n\n\nThe mean is unique to a specific set of values, i.e. there is only one mean for every data set. The mean is also relatively easy to calculate and is a well-known summary statistic.\n\n\n\n\n\n\n\n\n\n\n\nDisadvantages\n\n\nThe mean is easily influenced by extreme values. As an example. recall the mean of the following numbers:\n\nmean(c(5,27,26,30,31))\n\n[1] 23.8\n\n\nNow, if 31 was replaced by an extreme number, say 310, the new mean would be very different.\n\nmean(c(5,27,26,30,310))\n\n[1] 79.6",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#median",
    "href": "lecture2.html#median",
    "title": "Descriptive Statistics",
    "section": "Median",
    "text": "Median\nThe median is the middle value of ordered data.\n\n\n\n\n\n\nImportant\n\n\nIf there is an odd number of observations, the median is a value in the middle of the data.\nIf there is an even number of observations, the median is the average of the two middle values.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#median-example",
    "href": "lecture2.html#median-example",
    "title": "Descriptive Statistics",
    "section": "Median: Example",
    "text": "Median: Example\n\nExample 1: OddExample 2: Even\n\n\nWhat is the median of the following numbers? 83.07 72.15 89.61 81.68 87.26\n\nSort the values first in ascending order: 72.15, 81.68, 83.07, 87.26, 89.61\nThere are five values, which means there is a middle value (83.07). Hence, the median is 83.07.\n\n\n\nWhat is the median of the following numbers? 100 3 7 5 8 2\n\nSort the values first in ascending order: 2 3 5 7 8 100\nThere are six values, which means there is no middle value. We need to take the average of the two middle values (5,7). Hence, the median is (5+7)/2 = 6.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#median-r",
    "href": "lecture2.html#median-r",
    "title": "Descriptive Statistics",
    "section": "Median: R",
    "text": "Median: R\nIn R, we can use the median(vector) function.\n\nmedian(c(83.07, 72.15, 89.61, 81.68, 87.26))\n\n[1] 83.07\n\nmedian(c(100, 3, 7, 5, 8, 2))\n\n[1] 6\n\n\nThis works for variables in data frames.\n\nmedian(iris$Sepal.Length)\n\n[1] 5.8",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#median-exercise-in-r.",
    "href": "lecture2.html#median-exercise-in-r.",
    "title": "Descriptive Statistics",
    "section": "Median: Exercise in R.",
    "text": "Median: Exercise in R.\nThe data set USArrests contains statistics, in arrests per 100,000 residents for assault, murder, and rape in each of the 50 US states in 1973.\n\nExerciseAnswer\n\n\nCreate an ordered list for the Assault variable in USArrests. What is the median rate for assault per 100,000 residents?\n\n\n\nmedian(USArrests$Assault)\n\n[1] 159\n\n\nThe median arrest rate per 100,000 residents in the US in 1973 was 159.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#median-advantages-and-disadvantages",
    "href": "lecture2.html#median-advantages-and-disadvantages",
    "title": "Descriptive Statistics",
    "section": "Median: Advantages and Disadvantages",
    "text": "Median: Advantages and Disadvantages\n\n\n\n\n\n\n\nAdvantages\n\n\nThe median is unique to a specific set of values, i.e. there is only one median for every data set. The median is also relatively easy to calculate once the data is ordered. Unlike the mean, the median is NOT influenced by extreme values.\n\nmedian(c(5,27,26,30,31))\n\n[1] 27\n\n\nNow, if 31 was replaced by an extreme number, say 310, the new median would be the same because the middle part of the data did not change.\n\nmedian(c(5,27,26,30,310))\n\n[1] 27\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisadvantages\n\n\nWhile the median is a well-known summary statistic, it is limited in the area of inferential statistics. The mean is more versatile as an estimator when it comes to statistical tests compared to the median.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#mode",
    "href": "lecture2.html#mode",
    "title": "Descriptive Statistics",
    "section": "Mode",
    "text": "Mode\nFor a sample of quantitative/qualitative data, the mode is the value that occurs most frequently.\n\n\n\n\n\n\nImportant\n\n\nIf all values occurred with the same frequency, then the data does not have a mode.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#mode-example",
    "href": "lecture2.html#mode-example",
    "title": "Descriptive Statistics",
    "section": "Mode: Example",
    "text": "Mode: Example\nWhat is the mode of the following values? 33, 35, 35, 46, 21, 56, 390.\n\nThe mode is 35 because it occurred the most times.\n\nWhat is the mode of the following values? 21, 35, 35, 46, 21, 56, 390.\n\nThe modes are 21 and 35 because these values occurred twice, which was the highest frequency across the values.\n\nWhat is the mode of the following values? 33, 34, 35, 46, 21, 56, 390.\n\nThere is NO mode because all values occurred only once.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#mode-r",
    "href": "lecture2.html#mode-r",
    "title": "Descriptive Statistics",
    "section": "Mode: R",
    "text": "Mode: R\nWe can use the freq() or hist() functions in R to create a frequency table for the data set, but we often only need the frequency distribution. One function that we can use is the table function.\n\nfreq_table &lt;- table(iris$Sepal.Length)\nsort(freq_table,decreasing = TRUE)\n\n\n  5 5.1 6.3 5.7 6.7 5.5 5.8 6.4 4.9 5.4 5.6   6 6.1 4.8 6.5 4.6 5.2 6.2 6.9 7.7 \n 10   9   9   8   8   7   7   7   6   6   6   6   6   5   5   4   4   4   4   4 \n4.4 5.9 6.8 7.2 4.7 6.6 4.3 4.5 5.3   7 7.1 7.3 7.4 7.6 7.9 \n  3   3   3   3   2   2   1   1   1   1   1   1   1   1   1 \n\n\n\nfreq_table &lt;- table(iris$Species)\nsort(freq_table,decreasing = TRUE)\n\n\n    setosa versicolor  virginica \n        50         50         50 \n\n\nThe mode sepal length in the iris data set is 5. There is no mode for the species variable as all species occurred 50 times.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#mode-advantages-and-disadvantages",
    "href": "lecture2.html#mode-advantages-and-disadvantages",
    "title": "Descriptive Statistics",
    "section": "Mode: Advantages and Disadvantages",
    "text": "Mode: Advantages and Disadvantages\n\n\n\n\n\n\n\nAdvantages\n\n\nThe mode is easily calculable using frequency tables. Unlike the mean and median, it can be calculated for qualitative variables.\n\n\n\n\n\n\n\n\n\n\n\nDisadvantages\n\n\nThe mode is not unique as data sets can have more than one mode. Modes are not used in inferential statistics for quantitative variables.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#dispersion",
    "href": "lecture2.html#dispersion",
    "title": "Descriptive Statistics",
    "section": "Dispersion",
    "text": "Dispersion\nThe dispersion of a set of observations refers to the variability they exhibit. Measures of dispersion convey information on the spread of a data set.\n\n\n\n\n\n\nNote\n\n\nSmaller values of measures of dispersion indicate lower amount of dispersion.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#dispersion-example",
    "href": "lecture2.html#dispersion-example",
    "title": "Descriptive Statistics",
    "section": "Dispersion Example",
    "text": "Dispersion Example\nConsider populations A and B shown below.\n\nWhere are the population of values centered? Which population of values has a higher amount of dispersion?",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#measures-of-dispersion-1",
    "href": "lecture2.html#measures-of-dispersion-1",
    "title": "Descriptive Statistics",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nCommonly used measures of dispersion include:\n\nRange\nVariance\nStandard Deviation\nCoefficient of Variation\nInterquartile Range",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#range",
    "href": "lecture2.html#range",
    "title": "Descriptive Statistics",
    "section": "Range",
    "text": "Range\nThe range is the difference between the largest and smallest values in a set of observations.\n\\[\nR = x_L - x_S\n\\]\nwhere \\(x_L\\) and \\(x_S\\) are the largest and smallest values, respectively.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#range-example",
    "href": "lecture2.html#range-example",
    "title": "Descriptive Statistics",
    "section": "Range: Example",
    "text": "Range: Example\nWhat is the range of the following values: 254, 281, 192, 260, 212, 179?\n\nThe maximum value is 281, minimum value is 179. The range can be calculated as 281-179 = 102.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#range-r",
    "href": "lecture2.html#range-r",
    "title": "Descriptive Statistics",
    "section": "Range: R",
    "text": "Range: R\nThe diff(range(vector)) function calculates the range of a set of values.\n\nrange(c(254, 281, 192, 260, 212, 179))\n\n[1] 179 281\n\ndiff(range(c(254, 281, 192, 260, 212, 179)))\n\n[1] 102\n\n\nWe can also use max() and min() to identify the maximum and minimum values. We can take the difference between the two values to calculate the range.\n\nmax(c(254, 281, 192, 260, 212, 179))-min(c(254, 281, 192, 260, 212, 179))\n\n[1] 102",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#range-r-example",
    "href": "lecture2.html#range-r-example",
    "title": "Descriptive Statistics",
    "section": "Range: R Example",
    "text": "Range: R Example\nConsider the flights data set from the package nycflights23. The distance column contains the distance in miles between origin and destination airport for each flight. Calculate the range of the distances between origin and destination airports.\n\nmax(flights$distance)\n\n[1] 4983\n\nmin(flights$distance)\n\n[1] 80\n\nmax(flights$distance) - min(flights$distance)\n\n[1] 4903\n\n\nThe range is 4,903 miles.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#exercise-8",
    "href": "lecture2.html#exercise-8",
    "title": "Descriptive Statistics",
    "section": "Exercise",
    "text": "Exercise\nConsider the iris data set that gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris.\n\nExerciseAnswer\n\n\n\nWhat is the longest petal length in this data set?\nWhat is the shortest petal length in this data set?\nWhat is the range of the petal lengths?\n\n\n\n\nmax(iris$Petal.Length)\n\n[1] 6.9\n\nmin(iris$Petal.Length)\n\n[1] 1\n\nmax(iris$Petal.Length)-min(iris$Petal.Length)\n\n[1] 5.9",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#range-advantages-and-disadvantages",
    "href": "lecture2.html#range-advantages-and-disadvantages",
    "title": "Descriptive Statistics",
    "section": "Range: Advantages and Disadvantages",
    "text": "Range: Advantages and Disadvantages\n\n\n\n\n\n\n\nAdvantages\n\n\nThe main advantage in using the range is the simplicity of its computation. It also provides information on the span of the set of values.\n\n\n\n\n\n\n\n\n\n\n\nDisadvantages\n\n\nThe usefulness of the range is limited. The fact that it takes into account only two values causes it to be a poor measure of dispersion. It is often preferable to express the range as a number pair \\([x_S,x_L]\\), as is seen in some demographic tables in research papers.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#variance",
    "href": "lecture2.html#variance",
    "title": "Descriptive Statistics",
    "section": "Variance",
    "text": "Variance\nThe variance is a measure of how far the values are from the mean.\n\n\n\n\n\n\nImportant\n\n\nThe calculation for population and sample variances are slightly different. However, both involve taking the squared difference of each value and the mean of the data set.\n\n\n\n\nSample VariancePopulation Variance\\(s^2\\) vs. \\(\\sigma^2\\)\n\n\nThe sample variance is denoted by \\(s^2\\).\n\\[\ns^2 = \\frac{1}{(n-1)}\\sum_{i=1}^n (x_i-\\bar{x})^2\n\\]\n\n\nThe population variance is denoted by \\(\\sigma^2\\).For a population of size \\(N\\)\n\\[\n\\sigma^2 = \\frac{1}{(N)}\\sum_{i=1}^N (x_i-\\mu)^2\n\\]\n\n\nThe main difference between these two expressions is the denominator term (\\(n-1\\) vs. \\(N\\)). This discrepancy is due to a concept of degrees of freedom.\nThe assumption is that if the sample mean is known, we only need to know \\(n-1\\) values to fully define all the values in the data set. Hence, the denominator for the sample variance is \\(n-1\\).\n\n\n\n\n\n\nNote\n\n\nIn most realistic situations, we work with samples. Thus, we usually work with the sample variance.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#standard-deviation",
    "href": "lecture2.html#standard-deviation",
    "title": "Descriptive Statistics",
    "section": "Standard Deviation",
    "text": "Standard Deviation\nSince the variance involves squared differences, it does not have the same unit as the actual measurements. Hence, we typically use the standard deviation to measure the variability in a data set.\nThe standard deviation can be calculated by taking the square root of the variance.\n\\[\ns = \\sqrt{s^2}~~; ~~ \\sigma = \\sqrt{\\sigma^2}\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#standard-deviation-and-variance-r",
    "href": "lecture2.html#standard-deviation-and-variance-r",
    "title": "Descriptive Statistics",
    "section": "Standard Deviation and Variance: R",
    "text": "Standard Deviation and Variance: R\nThe respective functions sd(vector) and var(vector) calculates the sample standard deviation and variance for a set of values.\n\nExample 1 (Manual)Example 2 (R)Example 3\n\n\nCalculate the sample variance and standard deviation for the following numbers: 16, 10, 49, 15, 6.\nNote that the mean of the numbers is r mean(c(16, 10, 49, 15, 6))\n\\[\ns^2 = \\frac{1}{5-1}[(16-16)^2 + (10-16)^2 + (49-16)^2 + (15-16)^2 + (6-16)^2] = 293.7\n\\]\n\\[\ns = \\sqrt{s^2} = 17.1\n\\]\n\n\nUsing R functions, calculate the sample variance and standard deviation for the following numbers: 16, 10, 49, 15, 6.\n\nvar(c(16, 10, 49, 15, 6))\n\n[1] 293.7\n\nsd(c(16, 10, 49, 15, 6))\n\n[1] 17.13768\n\n\n\n\nUsing R functions, calculate the standard deviation and variance of the murder rates across the 50 US states in 1973. The rates are found in the dataset USArrests under the column Murder.\n\nsd(USArrests$Murder)\n\n[1] 4.35551\n\nvar(USArrests$Murder)\n\n[1] 18.97047",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#exercise-10",
    "href": "lecture2.html#exercise-10",
    "title": "Descriptive Statistics",
    "section": "Exercise",
    "text": "Exercise\nThe faithful data set includes data on a sample of 272 eruptions of the Old Faithful geyser in Yellowstone National Park. The column eruptions contains the eruption time in minutes.\n\nExerciseAnswer\n\n\nCalculate the following using R functions:\n\nMean eruption time\nEruption time variance\nEruption time standard deviation\n\n\n\nMean:\n\nmean(faithful$eruptions)\n\n[1] 3.487783\n\n\nStandard Deviation:\n\nsd(faithful$eruptions)\n\n[1] 1.141371\n\n\nVariance:\n\nvar(faithful$eruptions)\n\n[1] 1.302728",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#percentiles",
    "href": "lecture2.html#percentiles",
    "title": "Descriptive Statistics",
    "section": "Percentiles",
    "text": "Percentiles\n\n\n\n\n\n\n\nPercentiles\n\n\nThe \\(p\\)th percentile is the value \\(x\\) such that \\(p\\)% of the data are less than \\(x\\). For example, the 10th percentile is the value such that 10% of the data is below this number.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe 50th percentile is the median because half of the data (50%) is below the median. The maximum value is the 100th percentile, while the minimum value is the 0th percentile.\n\n\n\n\n\n\n\n\n\n\nQuartiles\n\n\nThe 25th percentile is also known as the first quartile and denoted as \\(Q_1\\). The 75th percentile is known as the third quartile (\\(Q_3\\)). The median is also known as the middle/second quartile (\\(Q_2\\)). These numbers are important in describing the variability and skewness in the data.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#interquartile-range-measure-of-dispersion",
    "href": "lecture2.html#interquartile-range-measure-of-dispersion",
    "title": "Descriptive Statistics",
    "section": "Interquartile Range (Measure of Dispersion)",
    "text": "Interquartile Range (Measure of Dispersion)\nThe interquartile range (IQR) is a measure of variation based on the measures of location. The IQR can be calculated by taking the difference between \\(Q_3\\) and \\(Q_1\\).\n\\[\nIQR = Q_3 - Q_1\n\\]\n\n\n\n\n\n\nNote\n\n\nThe main advantage of using IQR is its robustness to extreme values.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#percentiles-and-iqr-r",
    "href": "lecture2.html#percentiles-and-iqr-r",
    "title": "Descriptive Statistics",
    "section": "Percentiles and IQR: R",
    "text": "Percentiles and IQR: R\nYou can calculate the \\(p\\)th percentile of a set of values using the quantile(vector,p/100) function. The IQR can be calculated using the IQR(vector) function.\n\nExample 1Example 2\n\n\ncalculate the 25th percentile and 75th percentile of the eruption times (eruptions) of Old Faithful using the faithful data set.\n\nquantile(faithful$eruptions,0.25)\n\n    25% \n2.16275 \n\nquantile(faithful$eruptions,0.75)\n\n    75% \n4.45425 \n\n\n\n\nCalculate the IQR of the eruption times (eruptions) of Old Faithful using the faithful data set.\n\nIQR(faithful$eruptions)\n\n[1] 2.2915",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#exercise-12",
    "href": "lecture2.html#exercise-12",
    "title": "Descriptive Statistics",
    "section": "Exercise",
    "text": "Exercise\nThe infert data set includes data from a case-control study that investigates infertillity after spontaneous and induced abortion.\n\nExerciseAnswers\n\n\n\nUse glimpse() to determine the variables in the data set.\nCalculate the mean age for the entire sample.\nCalculate the standard deviation of the age for the entire sample.\nCalculate the variance of the age for the entire sample.\nCalculate the 90th percentile of the age for the entire sample.\nCalculate the IQR of the age for the entire sample.\n\n\n\n\nglimpse(infert)\n\nRows: 248\nColumns: 8\n$ education      &lt;fct&gt; 0-5yrs, 0-5yrs, 0-5yrs, 0-5yrs, 6-11yrs, 6-11yrs, 6-11y…\n$ age            &lt;dbl&gt; 26, 42, 39, 34, 35, 36, 23, 32, 21, 28, 29, 37, 31, 29,…\n$ parity         &lt;dbl&gt; 6, 1, 6, 4, 3, 4, 1, 2, 1, 2, 2, 4, 1, 3, 2, 2, 5, 1, 3…\n$ induced        &lt;dbl&gt; 1, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 2…\n$ case           &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ spontaneous    &lt;dbl&gt; 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1…\n$ stratum        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ pooled.stratum &lt;dbl&gt; 3, 1, 4, 2, 32, 36, 6, 22, 5, 19, 20, 37, 9, 29, 21, 18…\n\nmean(infert$age)\n\n[1] 31.50403\n\nsd(infert$age)\n\n[1] 5.251565\n\nvar(infert$age)\n\n[1] 27.57893\n\nquantile(infert$age,0.9)\n\n90% \n 39 \n\nIQR(infert$age)\n\n[1] 7.25\n\n\nMean: 31.5, Standard Deviation: 5.25, Variance: 27.58, 90th percentile: 39, IQR: 7.25",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#skewness-1",
    "href": "lecture2.html#skewness-1",
    "title": "Descriptive Statistics",
    "section": "Skewness",
    "text": "Skewness\nThe skewness provides information on the symmetry of data. If asymmetric, the data is said to be skewed.\n\n\n\n\n\n\nImportant\n\n\nThe direction of skewness depends on where the “tail” of the data is located.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#kurtosis",
    "href": "lecture2.html#kurtosis",
    "title": "Descriptive Statistics",
    "section": "Kurtosis",
    "text": "Kurtosis\nMeasures how flat/peaked a distribution is compared to a bell-shaped curve.\n\n\n\n\n\n\nImportant\n\n\nBell-shaped distributions are referred to as mesokurtic. Peaked distributions are referred to as leptokurtic. Flatter distributions are referred to as platykurtic.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#grammar-of-graphics",
    "href": "lecture2.html#grammar-of-graphics",
    "title": "Descriptive Statistics",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\nThe “grammar of graphics” defines a set of rules for constructing statistical graphics by combining different types of layers.\nWe can break a graphic into the following essential components:\n\ndata: dataset containing the variables of interest\ngeom: the geometric object in question, related to the type of plot we want to make\naes: the aesthetic attributes of the geometric object, such as color, shape, size, fill, etc.\nfacet: breaks up a plot into subplots as defined by the values of another variable",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#ggplot2-package",
    "href": "lecture2.html#ggplot2-package",
    "title": "Descriptive Statistics",
    "section": "ggplot2 package",
    "text": "ggplot2 package\nThe ggplot2 package includes the various components of the grammar of graphics.\n\n\n\n\n\n\nNote\n\n\nThe ggplot() function is used to create a base for the plot which includes the following:\n\nThe data frame where the variables to be plotted belong (data)\nThe mapping of the aesthetic attributes of the plot.\n\nThe geometry and type of plot will be added as layers to the ggplot() function using the + symbol.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#common-graphs",
    "href": "lecture2.html#common-graphs",
    "title": "Descriptive Statistics",
    "section": "Common Graphs",
    "text": "Common Graphs\nHere are common plots used in exploring data:\n\nhistograms\nbar plots\nboxplots",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#histograms",
    "href": "lecture2.html#histograms",
    "title": "Descriptive Statistics",
    "section": "Histograms",
    "text": "Histograms\nHistograms are plots that visualize the distribution of a numerical value.\n\n\n\n\n\n\nNote\n\n\nHistograms are graphical representations of the frequency table/distribution.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#histograms-in-ggplot",
    "href": "lecture2.html#histograms-in-ggplot",
    "title": "Descriptive Statistics",
    "section": "Histograms in ggplot()",
    "text": "Histograms in ggplot()\n\nExampleNotes\n\n\nConsider the infert data set in R. Suppose we want to visualize the distribution of the participant age in the case-control study.\n\nlibrary(tidyverse) #includes ggplot2\n1ggplot(data=infert, aes(x=age)) +\n2  geom_histogram(bins=40)\n\n\n1\n\nBase layer defining what the source data set is (data=infert) and the aesthetic aes(x=age).\n\n2\n\ngeom_histogram() adds the layer of a histogram on the base layer, using 40 bins.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe geom_histogram() function creates a histogram layer on top of the base created by ggplot(). You can add other modifications to the histogram (e.g. color, fill, etc.) in the geom_histogram() function.\n\n\n\n\nggplot(data=infert, aes(x=age)) +\n  geom_histogram(bins=40, color=\"white\", fill=\"blue\")",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#bar-plots-in-ggplot",
    "href": "lecture2.html#bar-plots-in-ggplot",
    "title": "Descriptive Statistics",
    "section": "Bar plots in ggplot()",
    "text": "Bar plots in ggplot()\nBar plots are typically used to visualize the frequency distribution for a categorical variable.\n\n\n\n\n\n\nImportant\n\n\ngeom_bar() is used to create bar plots in the ggplot2 package.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#bar-plots-in-ggplot-1",
    "href": "lecture2.html#bar-plots-in-ggplot-1",
    "title": "Descriptive Statistics",
    "section": "Bar plots in ggplot()",
    "text": "Bar plots in ggplot()\n\nExampleNotes 1Notes 2\n\n\nConsider the infert data set in R. Suppose we want to visualize the distribution of the education level (in years) in the case-control study.\n\nlibrary(tidyverse) #includes ggplot2\n1ggplot(data=infert, aes(x=education)) +\n2  geom_bar()\n\n\n1\n\nBase layer defining what the source data set is (data=infert) and the aesthetic aes(x=education).\n\n2\n\ngeom_bar() adds the layer of a bar plot on the base layer.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nLike geom_histogram(), you can add other modifications to the histogram (e.g. color, fill, etc.) in the geom_bar() function.\n\n\n\n\nggplot(data=infert, aes(x=education)) + \n  geom_bar(color=\"white\", fill=\"blue\", width=0.5)\n\n\n\n\n\n\n\n\n\n\nYou can create side-by-side bar plots by facetting. facet_wrap allows you to create bar plots across the levels of another variable of interest. Suppose we want to visualize the distribution of education level for the case (1) and control (0) groups.\n\nggplot(data=infert, aes(x=education)) + \n  geom_bar(color=\"white\", fill=\"blue\", width=0.5) + \n  facet_wrap(~case)",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#boxplots",
    "href": "lecture2.html#boxplots",
    "title": "Descriptive Statistics",
    "section": "Boxplots",
    "text": "Boxplots\nBoxplots are another way to visualize the distribution of a numerical value. Boxplots are constructed from the information provided in the five-number summary.\n\n\n\n\n\n\n\nFive-Number Summary\n\n\nThe five-number summary of a set of values include the following statistics:\n\nMinimum\nFirst Quartile\nMedian\nThird Quartile\nMaximum",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#boxplots-in-ggplot",
    "href": "lecture2.html#boxplots-in-ggplot",
    "title": "Descriptive Statistics",
    "section": "Boxplots in ggplot()",
    "text": "Boxplots in ggplot()\n\n\n\n\n\n\nNote\n\n\nThe function geom_boxplot() is used to create boxplots in the ggplot2 package.\n\n\n\nBoxplots can also provide information on how skewed the data distribution is by the location of the mediam with respect to the “box”.\n\n\n\n\n\n\nImportant\n\n\nIf the median is closer to the first quartile, the data is right-skewed. If the median is closer to the third quartile, the data is left-skewed. If the median is in the middle, then the data is symmetric/unskewed.",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#boxplots-in-ggplot-1",
    "href": "lecture2.html#boxplots-in-ggplot-1",
    "title": "Descriptive Statistics",
    "section": "Boxplots in ggplot()",
    "text": "Boxplots in ggplot()\n\nExampleNotes 1Notes 2\n\n\nConsider the USArrests data set. Create a box plot for the arrest rate for assault as given by the Assault variable.\n\nggplot(data=USArrests, aes(x=\"Assault\",y=Assault)) + geom_boxplot()\n\n\n\n\n\n\n\n\nThe data appears to be slightly right-skewed because the median is closer to \\(Q_1\\) than \\(Q_3\\).\n\n\nYou can also orient boxplots horizontally and overlay the data points using geom_point().\n\nggplot(data=USArrests, aes(y=\"Assault\",x=Assault)) + geom_boxplot() + geom_point()\n\n\n\n\n\n\n\n\n\n\nYou can also create separate boxplots for different groups as dictated by a separate variable. Consider the iris data set. I can create side-by-side boxplots of petal lengths corresponding to each species.\n\nggplot(data=iris,aes(x=Species,y=Petal.Length)) + geom_boxplot() + geom_point()",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#importing-files",
    "href": "lecture2.html#importing-files",
    "title": "Descriptive Statistics",
    "section": "Importing files",
    "text": "Importing files\nThere are multiple ways to import files into R. The most common data set format is the .csv file. You can import CSV files using the read.csv(filename) function.\nFirst, download the file SleepHealthData.csv from Canvas in the same folder as your R source code.\n\ngetwd() # save your data in this folder\n\n[1] \"C:/Users/migsf/OneDrive/Documents/GitHub/EAB703-Slides-2025\"\n\nsleep &lt;- read.csv(\"SleepHealthData.csv\") # or use a specific path to your folder\nglimpse(sleep)\n\nRows: 374\nColumns: 13\n$ person_id               &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…\n$ gender                  &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\"…\n$ age                     &lt;int&gt; 27, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29…\n$ occupation              &lt;chr&gt; \"Software Engineer\", \"Doctor\", \"Doctor\", \"Sale…\n$ sleep_duration          &lt;dbl&gt; 6.1, 6.2, 6.2, 5.9, 5.9, 5.9, 6.3, 7.8, 7.8, 7…\n$ quality_of_sleep        &lt;int&gt; 6, 6, 6, 4, 4, 4, 6, 7, 7, 7, 6, 7, 6, 6, 6, 6…\n$ physical_activity_level &lt;int&gt; 42, 60, 60, 30, 30, 30, 40, 75, 75, 75, 30, 75…\n$ stress_level            &lt;int&gt; 6, 8, 8, 8, 8, 8, 7, 6, 6, 6, 8, 6, 8, 8, 8, 8…\n$ bmi_category            &lt;chr&gt; \"Overweight\", \"Normal\", \"Normal\", \"Obese\", \"Ob…\n$ blood_pressure          &lt;chr&gt; \"126/83\", \"125/80\", \"125/80\", \"140/90\", \"140/9…\n$ heart_rate              &lt;int&gt; 77, 75, 75, 85, 85, 85, 82, 70, 70, 70, 70, 70…\n$ daily_steps             &lt;int&gt; 4200, 10000, 10000, 3000, 3000, 3000, 3500, 80…\n$ sleep_disorder          &lt;chr&gt; \"None\", \"None\", \"None\", \"Sleep Apnea\", \"Sleep …",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture2.html#exercise-14",
    "href": "lecture2.html#exercise-14",
    "title": "Descriptive Statistics",
    "section": "Exercise",
    "text": "Exercise\nWe will use the sleep data set we just imported into R from the csv file.\n\nExerciseAnswer\n\n\nCreate a plot that shows the distribution of sleep duration (sleep_duration) for different sleep disorders (sleep_disorder).\n\n\n\nggplot(data=sleep,aes(x=sleep_disorder,y=sleep_duration)) + geom_boxplot() + geom_point()",
    "crumbs": [
      "Lectures",
      "Lecture 2- Descriptive Statistics"
    ]
  },
  {
    "objectID": "lecture4.html#discrete-random-variables",
    "href": "lecture4.html#discrete-random-variables",
    "title": "Probability Distributions",
    "section": "Discrete Random Variables",
    "text": "Discrete Random Variables\n\n\n\n\n\n\n\nDiscrete Random Variable\n\n\nA random variable is discrete if it can only take on a finite or countably infinite number of values.\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nIntegers are countably infinite, hence counts are considered discrete.\nQualitative variables often take on a finite number of values.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#discrete-probability-distribution",
    "href": "lecture4.html#discrete-probability-distribution",
    "title": "Probability Distributions",
    "section": "Discrete Probability Distribution",
    "text": "Discrete Probability Distribution\nThe probability distribution of a discrete random variable is a table, graph, formula, or other device used to specify all possible values of a discrete random variable along with their respective probabilities.\n\n\n\n\n\n\nTip\n\n\nFormulas that describe discrete probability distributions are also known as the probability mass function (pmf). The function is often denoted as \\(P(X=x)\\), \\(p_X(x)\\), or simply \\(p(x)\\).\n\n\n\n\n\n\n\n\n\nImportant\n\n\nNotation is important here. \\(X\\) is the random variable, \\(x\\) is the outcome/realization. \\(X=x\\) is the event that the random variable is equal to the outcome \\(x\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-1",
    "href": "lecture4.html#example-1",
    "title": "Probability Distributions",
    "section": "Example 1",
    "text": "Example 1\nConsider a random variable \\(X\\) that represents the outcome of a fair six-sided die. Prior to rolling the die, \\(X\\) can take on any one of the six values: {1,2,3,4,5,6}. The discrete probability distribution can be expressed in the following forms:\n\nTableFormulaGraphNotes\n\n\n\n\n\nOutcome of \\(X\\)\np(x)\n\n\n\n\n1\n1/6\n\n\n2\n1/6\n\n\n3\n1/6\n\n\n4\n1/6\n\n\n5\n1/6\n\n\n6\n1/6\n\n\n\n\n\n\\[\np(x) = \\begin{cases}\n      1/6,~ if~x=1,2,...,6 \\\\\n      0, ~ otherwise\n   \\end{cases}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nHere, \\(X\\) is the result of rolling the die, \\(x\\) is the outcome measured after rolling the die which can be any of the following numbers: {1,2,3,4,5,6}.\n\n\n\nThis PMF is also referred to as a uniform discrete distribution because the probability is uniformly distributed across the sample space.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-2.1",
    "href": "lecture4.html#example-2.1",
    "title": "Probability Distributions",
    "section": "Example 2.1",
    "text": "Example 2.1\nThe frequency table below shows the results of a survey in which participants residing in the Appalachian region of southern Ohio were asked how many food assistance programs they had used in the last 12 months.\n\nFrequency TableProbability DistributionGraph\n\n\n\n\n\nNumber of Programs\nFrequency\n\n\n\n\n1\n62\n\n\n2\n47\n\n\n3\n39\n\n\n4\n39\n\n\n5\n58\n\n\n6\n37\n\n\n7\n4\n\n\n8\n11\n\n\nTotal\n297\n\n\n\n\n\nWe can calculate the probability distribution by calculating the relative frequency of each outcome. This can be done by dividing the frequencies by the total (297).\n\ndf &lt;- data.frame(`Number of Programs`=factor(c(1:8), levels=c(1:8)),\nFrequency = c(62,47,39,39,58,37,4,11),\nRelative.Frequency = c(62,47,39,39,58,37,4,11)/297) \n\ndf\n\n  Number.of.Programs Frequency Relative.Frequency\n1                  1        62         0.20875421\n2                  2        47         0.15824916\n3                  3        39         0.13131313\n4                  4        39         0.13131313\n5                  5        58         0.19528620\n6                  6        37         0.12457912\n7                  7         4         0.01346801\n8                  8        11         0.03703704\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x=Number.of.Programs,y=Relative.Frequency)) + \n1  geom_col(fill=\"gray\",color=\"black\") +\n2  theme_bw() +\n3  labs(x=\"Number of Programs\",y=\"p(x)\")\n\n\n1\n\nFormatting the bar plot with a gray fill and black outline\n\n2\n\ntheme_bw using a black and white theme, which looks good aesthetically\n\n3\n\nAxes labels were changed.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-2.2",
    "href": "lecture4.html#example-2.2",
    "title": "Probability Distributions",
    "section": "Example 2.2",
    "text": "Example 2.2\nConsider the probability distribution in Example 2.1.\n\nWhat is the probability of randomly selecting a family who used four assistance programs?\n\n\\(p(4) = 0.1313\\)\n\nWhat is the probability of randomly selecting a family who used one or three assistance programs?\n\n\n\n\n\n\n\nImportant\n\n\nThese events are disjoint, hence P(one AP AND three AP 0) = 0. Using the addition rule,\n\\(P(one~ \\cup~ three) = P(one) + P(three) =\\) 0.34",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#pmf-properties",
    "href": "lecture4.html#pmf-properties",
    "title": "Probability Distributions",
    "section": "PMF: Properties",
    "text": "PMF: Properties\nThe discrete probability distribution should satisfy the following properties:\n\n\\(0 \\leq p(x) \\leq 1\\) for all \\(x\\).\n\\(\\sum_{all~x} p(x) = 1\\) (The sum of the probabilities of all disjoint outcomes in the sample space is \\(1\\).)",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#cumulative-distributions",
    "href": "lecture4.html#cumulative-distributions",
    "title": "Probability Distributions",
    "section": "Cumulative Distributions",
    "text": "Cumulative Distributions\nIn addition to discrete probability distributions, discrete variables also have cumulative distribution functions (CDF)\n\n\n\n\n\n\nTip\n\n\nThe CDF for a discrete variable can be calculated by successively adding the probabilities of the outcome of interest and others before it.\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe CDF is often referred to as \\(F_X(x)\\) or \\(F(x)\\) to signify \\(P(X \\leq x)\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-1-1",
    "href": "lecture4.html#example-1-1",
    "title": "Probability Distributions",
    "section": "Example 1",
    "text": "Example 1\nConsider the PMF of the fair six-sided die. The cumulative distribution can be calculated using the cumulative relative frequency.\n\n\n\nOutcome of \\(X\\)\np(x)\nF(x) = P(X\\(\\leq\\)x)\n\n\n\n\n1\n1/6\n1/6\n\n\n2\n1/6\n2/6\n\n\n3\n1/6\n3/6\n\n\n4\n1/6\n4/6\n\n\n5\n1/6\n5/6\n\n\n6\n1/6\n6/6",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-2",
    "href": "lecture4.html#example-2",
    "title": "Probability Distributions",
    "section": "Example 2",
    "text": "Example 2\nConsider the PMF for the food assistance example. We can calculate and visualize the cumulative relative frequency using R.\n\nTableGraph\n\n\nTo create a separate table as a function of existing tables, we use the mutate(data_frame,expr) function in the dplyr package available in tidyverse. The cumulative sum can also be calculated automatically using the cumsum(column_name) function\n\ndf &lt;- data.frame(`Number of Programs`=1:8,\nFrequency = c(62,47,39,39,58,37,4,11),\nRelative.Frequency = c(62,47,39,39,58,37,4,11)/297) \n\nmutate(df,Cumulative.Relative.Frequency = cumsum(Relative.Frequency))\n\n  Number.of.Programs Frequency Relative.Frequency Cumulative.Relative.Frequency\n1                  1        62         0.20875421                     0.2087542\n2                  2        47         0.15824916                     0.3670034\n3                  3        39         0.13131313                     0.4983165\n4                  4        39         0.13131313                     0.6296296\n5                  5        58         0.19528620                     0.8249158\n6                  6        37         0.12457912                     0.9494949\n7                  7         4         0.01346801                     0.9629630\n8                  8        11         0.03703704                     1.0000000\n\n\n\n\nThe plot of the cumulative distribution function is called an ogive. The option stat_ecdf provides us with a way to create ogives based on frequency values.\n\nggplot(df, aes(x=Number.of.Programs, y=Frequency)) +\n1  stat_ecdf(geom=\"step\") + stat_ecdf(geom=\"point\",color=\"blue\",size=2) +\n  theme_bw() + \n2  scale_x_continuous(breaks=c(1:8))+\n  labs(x=\"Number of Programs\",y=\"F(x)\") \n\n\n1\n\n“step” creates the lines in the ogive, while “point” shows the points corresponding to the values of F(x). The vertical lines are uninterpretable; they only provide a visual cue for the jump from one value to another.\n\n2\n\nThe scale_x_continuous(breaks=c(1:8)) statement tells R to show all the points between 1 and 8 in the graph. This way, it is easier to interpret for other readers.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-2.1-1",
    "href": "lecture4.html#example-2.1-1",
    "title": "Probability Distributions",
    "section": "Example 2.1",
    "text": "Example 2.1\nConsider the food assistance example. What is the probability of randomly selecting a family that have used less than three assistance programs.\n\n\nCode\ndf &lt;- data.frame(`Number of Programs`=1:8,\nFrequency = c(62,47,39,39,58,37,4,11),\nRelative.Frequency = c(62,47,39,39,58,37,4,11)/297) \n\nmutate(df,Cumulative.Relative.Frequency = cumsum(Relative.Frequency))\n\n\n  Number.of.Programs Frequency Relative.Frequency Cumulative.Relative.Frequency\n1                  1        62         0.20875421                     0.2087542\n2                  2        47         0.15824916                     0.3670034\n3                  3        39         0.13131313                     0.4983165\n4                  4        39         0.13131313                     0.6296296\n5                  5        58         0.19528620                     0.8249158\n6                  6        37         0.12457912                     0.9494949\n7                  7         4         0.01346801                     0.9629630\n8                  8        11         0.03703704                     1.0000000\n\n\n\n\n\n\n\n\nTip\n\n\nLess than three assistance programs can also mean “two or less programs” or “at most two programs”. Hence, we are interested in \\(F(2)\\)\n\\(F(2) = P(X \\leq 2) = P(X=1) + P(X=2)=\\) 0.367",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#exercise",
    "href": "lecture4.html#exercise",
    "title": "Probability Distributions",
    "section": "Exercise",
    "text": "Exercise\nConsider the food assistance example.\n\nQuestionAnswer\n\n\nWhat is the probability that a randomly selected family utilized at least 4 programs?\n\n\nCode\ndf &lt;- data.frame(`Number of Programs`=1:8,\nFrequency = c(62,47,39,39,58,37,4,11),\nRelative.Frequency = c(62,47,39,39,58,37,4,11)/297) \n\nmutate(df,Cumulative.Relative.Frequency = cumsum(Relative.Frequency))\n\n\n  Number.of.Programs Frequency Relative.Frequency Cumulative.Relative.Frequency\n1                  1        62         0.20875421                     0.2087542\n2                  2        47         0.15824916                     0.3670034\n3                  3        39         0.13131313                     0.4983165\n4                  4        39         0.13131313                     0.6296296\n5                  5        58         0.19528620                     0.8249158\n6                  6        37         0.12457912                     0.9494949\n7                  7         4         0.01346801                     0.9629630\n8                  8        11         0.03703704                     1.0000000\n\n\n\n\nThere are two ways to approach this question.\n\n\n\n\n\n\nTip\n\n\nApproach 1: Sum the relative frequencies from \\(X=4\\) to the maximum possible value (\\(X=8\\)).\n\\(p(4) + p(5) + p(6) + p(7) + p(8)\\) = 0.1313+0.1953+0.1246+0.0135+0.0370 = 0.50167\n\n\n\n\n\n\n\n\n\nTip\n\n\nApproach 2: Use the complement principle. To isolate the families who utilized at least 4 programs, we must remove those who utilized three programs or less. Then,\n\\(p(4) + p(5) + p(6) + p(7) + p(8)\\) = 1-F(3) = 1-0.4983 = 0.5017",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#expectation-values-of-discrete-probability-distributions",
    "href": "lecture4.html#expectation-values-of-discrete-probability-distributions",
    "title": "Probability Distributions",
    "section": "Expectation Values of Discrete Probability Distributions",
    "text": "Expectation Values of Discrete Probability Distributions\nThe expected value of a random variable can be thought of as the average of a very large number of observations of the random variable.\n\n\n\n\n\n\nTip\n\n\nThe expected value of \\(X\\), denoted by \\(E(X)\\), can be calculated by taking the sum of the products of each outcome {\\(x_1,x_2,...,\\)} and their corresponding probabilities {\\(p(x_1),p(x_2),...\\)}. In mathematical terms,\n\\[\nE(X)= \\sum_i x_i p(x_i)\n\\]\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\\(E(X)\\) is also the mean of the discrete probability distribution, \\(\\mu\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example",
    "href": "lecture4.html#example",
    "title": "Probability Distributions",
    "section": "Example",
    "text": "Example\nConsider a random variable \\(X\\) that represents the outcome of a fair six-sided die. Prior to rolling the die, \\(X\\) can take on any one of the six values: {1,2,3,4,5,6}. The probability distribution is shown below:\n\nProbability DistributionCalculation\n\n\n\n\n\nOutcome of \\(X\\)\np(x)\n\n\n\n\n1\n1/6\n\n\n2\n1/6\n\n\n3\n1/6\n\n\n4\n1/6\n\n\n5\n1/6\n\n\n6\n1/6\n\n\n\n\n\n\\(E(X)\\) can be calculated using the formula as shown below:\n\\[\nE(X) = 1(1/6)+2(1/6)+3(1/6)+4(1/6)+5(1/6)+6(1/6)\n\\]\nThe result leads to \\(E(X)=\\) 3.5",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#exercise-1",
    "href": "lecture4.html#exercise-1",
    "title": "Probability Distributions",
    "section": "Exercise",
    "text": "Exercise\nConsider the food assistance example. What is the mean number of assistance programs used based on the PMF provided?\n\nPMFAnswer\n\n\n\n\n  Number.of.Programs Frequency Relative.Frequency\n1                  1        62         0.20875421\n2                  2        47         0.15824916\n3                  3        39         0.13131313\n4                  4        39         0.13131313\n5                  5        58         0.19528620\n6                  6        37         0.12457912\n7                  7         4         0.01346801\n8                  8        11         0.03703704\n\n\n\n\n\\(E(X) = \\sum_i x_i p(x_i)\\) translates to:\nE(X) = 1(0.2087)+2(0.1582) + 3(0.1313) + 4(0.1313) + 5(0.1953) + 6(0.1246) + 7(0.0135) + 8(0.037).\nThis results to \\(E(X)=\\) 3.559",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#expectation-value-of-functions",
    "href": "lecture4.html#expectation-value-of-functions",
    "title": "Probability Distributions",
    "section": "Expectation Value of Functions",
    "text": "Expectation Value of Functions\nExpectation values can also be calculated for functions.\n\n\n\n\n\n\nTip\n\n\nThe expected value of a function \\(g(X)\\), denoted by \\(E[g(X)]\\), can be calculated by taking the sum of the products of each function evaluated at the outcome {\\(g(x_1),g(x_2),...,\\)} and their corresponding probabilities {\\(p(x_1),p(x_2),...\\)}. In mathematical terms,\n\\[\nE[g(X)]= \\sum_i g(x_i) p(x_i)\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#variance-and-standard-deviation",
    "href": "lecture4.html#variance-and-standard-deviation",
    "title": "Probability Distributions",
    "section": "Variance and Standard Deviation",
    "text": "Variance and Standard Deviation\nThe variance of the discrete probability distribution can be calculated using expectation values as well. The variance \\(\\sigma^2\\) can be expressed as \\(E[(X-\\mu)^2]\\).\n\\[\n\\sigma^2 = E[(X-\\mu)^2] = \\sum_i (x_i-\\mu)^2 p(x_i)\n\\]\nThe standard deviation can be calculated by taking taking the square root of the variance.\n\\[\n\\sigma = \\sqrt{\\sigma^2}\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-3",
    "href": "lecture4.html#example-3",
    "title": "Probability Distributions",
    "section": "Example",
    "text": "Example\nWhat is the variance and standard deviation of the probability distribution for rolling a fair six-sided die?\n\nNotesAnswer\n\n\nIn calculating the variance, it would be easier to use R. First, we would need to create a data frame for the probability distribution:\n\ndf &lt;- data.frame(Outcome = 1:6,\n                 Prob = rep(1/6,6))\n\ndf\n\n  Outcome      Prob\n1       1 0.1666667\n2       2 0.1666667\n3       3 0.1666667\n4       4 0.1666667\n5       5 0.1666667\n6       6 0.1666667\n\n\n\n\n\nmu &lt;- sum(df$Outcome*df$Prob)\nmu\n\n[1] 3.5\n\nsigma_2 &lt;- sum((df$Outcome-mu)^2*df$Prob)\nsigma_2\n\n[1] 2.916667\n\n\nThe variance is 2.9166667",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#bernoulli-trials",
    "href": "lecture4.html#bernoulli-trials",
    "title": "Probability Distributions",
    "section": "Bernoulli Trials",
    "text": "Bernoulli Trials\nA random process, also referred to as a trial, can result in only one of two mutually exclusive outcomes is called a Bernoulli trial.\n\n\n\n\n\n\nNote\n\n\nExamples of Bernoulli trials include dichotomous random variables such as mortality (dead/alive), coin tosses (heads/tails), and infections (infected/not infected).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#bernoulli-process",
    "href": "lecture4.html#bernoulli-process",
    "title": "Probability Distributions",
    "section": "Bernoulli Process",
    "text": "Bernoulli Process\n\n\n\n\n\n\nImportant\n\n\nA sequence of Bernoulli trials forms a Bernoulli process. Bernoulli processes have the following characteristics:\n\nThe experiment consists of exactly \\(n\\) identical trials\nEach trial can have only one of two outcomes (success/failure)\nThe probability of success, \\(p\\) is constant for every trial. The probability of failure, \\(q\\), is equal to \\(1-p\\).\nThe trials are independent\nThe random variable of interest is the number of successes \\(X\\) out of the \\(n\\) trials.\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nImagine flipping a coin \\(n\\) times. The random variable \\(X\\) can be the number of heads observed after \\(n\\) flips.\n\nSuccess: Flipping a head, Failure: Flipping a tail\nProbability of success, \\(p\\) is 0.50 for a fair coin.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#binomial-distribution-1",
    "href": "lecture4.html#binomial-distribution-1",
    "title": "Probability Distributions",
    "section": "Binomial distribution",
    "text": "Binomial distribution\nThe random variable \\(X\\) described in the Bernoulli process follows the Binomial distribution.\n\n\n\n\n\n\n\nBinomial Distribution\n\n\nThe probability mass function (PMF) of a binomial random variable \\(X\\) with parameters \\(n\\) and \\(p\\) is:\n\\[\np(x) = \\frac{n!}{x!(n-x)!} p^x (1-p)^{n-x}\n\\]\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nIf a random variable \\(X\\) follows the binomial distribution with \\(n\\) trials and success probability \\(p\\), we can use the following notation: \\(X \\sim BIN(n,p)\\)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\\(n!\\) is the factorial of a non-negative integer \\(n\\). The factorial is the product of all the positive integers less than or equal to n.\n\\[\nn! = n(n-1)(n-2)...(2)(1)\n\\]\nWith the special case \\(0!=1\\)",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#dissecting-the-binomial-distribution-independent-events",
    "href": "lecture4.html#dissecting-the-binomial-distribution-independent-events",
    "title": "Probability Distributions",
    "section": "Dissecting the Binomial Distribution: Independent Events",
    "text": "Dissecting the Binomial Distribution: Independent Events\nSuppose we toss a coin three times, each toss independent of each other. Assuming the probability of getting heads is \\(p\\), the probability of flipping two heads out of three tosses can be calculated using the property of independent events.\n\\[\nP(2 heads) = pp(1-p)(1-p) = p^2 (1-p)^1 = p^2 (1-p)^{(3-2)}\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#dissecting-the-binomial-distribution-counting-sample-points",
    "href": "lecture4.html#dissecting-the-binomial-distribution-counting-sample-points",
    "title": "Probability Distributions",
    "section": "Dissecting the Binomial Distribution: Counting Sample Points",
    "text": "Dissecting the Binomial Distribution: Counting Sample Points\nHowever, the probability measured using independent events does not account for the multiple configurations of flipping two heads out of three tosses.\n\nResultsNotes\n\n\n\n\n\n\n\n\nWarning\n\n\nFlipping two heads out of three tosses could lead to the following results: HTH, HHT, THH.\n\n\n\n\n\nNote that the order in flipping the two heads does not matter; what matters is counting the number of ways that the two heads can occur after three tosses. These results are disjoint with the same probability \\(p^2(1-p)\\). The probability that any of these results occur can be calculated using the addition rule:\n\\[\nP(2heads) = P(HTH)+P(HHT) + P(THH)= 3p^2(1-p)\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#combination",
    "href": "lecture4.html#combination",
    "title": "Probability Distributions",
    "section": "Combination",
    "text": "Combination\nHow do we account for the number of sample points when we consider 100 tosses instead of 3?\n\n\n\n\n\n\n\nCombination\n\n\nThe unordered selection of \\(x\\) successes out of \\(n\\) trias is called a combination, also denoted by \\(C(n,x)\\).\n\\[\nC(n,x) = \\frac{n!}{x!(n-x)!}\n\\]\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nUsing combinations for the three toss example, \\(n=3\\), \\(x=2\\).\n\\[\nC(3,2) = \\frac{3!}{2!(3-2)!} = 3\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#binomial-distribution-in-r",
    "href": "lecture4.html#binomial-distribution-in-r",
    "title": "Probability Distributions",
    "section": "Binomial Distribution in R",
    "text": "Binomial Distribution in R\nR is handy for handling binomial random variables.\n\nCombinationPMFCDFRandom Binomial Numbers\n\n\nchoose(n,x) can calculate the number of combinations of \\(x\\) successes in \\(n\\) trials.\n\n\ndbinom(x,n,p) can calculate the PMF of the binomial distribution for an outcome of \\(x\\) successes out of \\(n\\) trials with success probability \\(p\\).\n\n\npbinom(x,n,p) can calculate the CDF of the binomial distribution for an outcome of \\(x\\) successes out of \\(n\\) trials with success probability \\(p\\).\n\n\nrbinom(k,n,p) generates k numbers for a binomial distribution with number of trials \\(n\\) and success probability \\(p\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#binomial-distribution-visualization",
    "href": "lecture4.html#binomial-distribution-visualization",
    "title": "Probability Distributions",
    "section": "Binomial Distribution: Visualization",
    "text": "Binomial Distribution: Visualization\n\nBIN(10,0.5)BIN(10,0.7)BIN(10,0.2)",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-4",
    "href": "lecture4.html#example-4",
    "title": "Probability Distributions",
    "section": "Example",
    "text": "Example\nSuppose we toss a fair coin (\\(p\\)=0.5) three times, each toss independent of each other.\n\nQuestionsPMF (Math)PMF (R)\\(P(X\\leq 2)\\)Simulation\n\n\n\nWhat is the probability of flipping heads twice?\n\nCalculate manually using the equation for \\(p(x)\\).\nCalculate using R.\n\nWhat is the probability of flipping at most two heads? Calculate using R.\nSimulate this binomial process 10 times using rbinom()\n\n\n\n\\(p(x) = C(3,2)(0.5)^2(1-0.5) = 3(0.5)^2(1-0.5)=\\) 0.375\n\n\n\ndbinom(2,3,0.5)\n\n[1] 0.375\n\n\n\n\n\\(P(X\\leq 2)\\) corresponds to the value of the CDF at \\(x=2\\) (\\(F(2)\\)).\n\npbinom(2,3,0.5)\n\n[1] 0.875\n\ndbinom(0,3,0.5) + dbinom(1,3,0.5) + dbinom(2,3,0.5)\n\n[1] 0.875\n\n\nYou can also use the complementary principle. The complement of \\(X \\leq 2\\) is \\(X=3\\).\n\n1- dbinom(3,3,0.5)\n\n[1] 0.875\n\n\n\n\n\nNsim&lt;- 10 # Simulating 10 times\n1set.seed(12)\nsims &lt;- rbinom(Nsim,3,0.5)\nsims\n\n\n1\n\nSetting a seed enables us to draw the same numbers from the binomial distribution.\n\n\n\n\n [1] 0 2 3 1 1 0 1 2 0 0\n\n\nWe can create a bar plot for the simulations.\n\ndf &lt;- data.frame(simulations=sims)\nggplot(df, aes(x=simulations)) + \n  geom_histogram() + \n  theme_bw() + \n  labs(x=\"Number of Heads\", y=\"Count\")",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#exercise-2",
    "href": "lecture4.html#exercise-2",
    "title": "Probability Distributions",
    "section": "Exercise",
    "text": "Exercise\nIn 2021, 8.9% of US adults were diagnosed with diabetes (Types I and II) CDC.\n\nQuestionsAnswerSimulation\n\n\nWhat is the probability that out of a sample of 250 adults in 2021,\n\nExactly 45 have diabetes\nBetween 30 and 60, inclusive, have diabetes\nSimulate the sampling process 100 times and create a histogram of the count of participants diagnosed with diabetes out of 250 adults.\n\n\n\n\nExactly 45 have diabetes\n\n\ndbinom(45,250,0.089)\n\n[1] 2.638007e-06\n\n\n\nBetween 30 and 60, inclusive, have diabetes: \\(30 \\leq x \\leq 60\\)\n\n\npbinom(60,250,0.089) - pbinom(29,250,0.089)\n\n[1] 0.05825713\n\n\n\n\n\nNsim&lt;- 100 # Simulating 10 times\nset.seed(12)\nsims &lt;- rbinom(Nsim,250,0.089)\ndf &lt;- data.frame(simulations=sims)\nggplot(df, aes(x=simulations)) + \n  geom_histogram(binwidth=1) + \n  theme_bw() + \n  labs(x=\"Number of Diagnosed Diabetics\", y=\"Count\")",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#expected-value-and-variance",
    "href": "lecture4.html#expected-value-and-variance",
    "title": "Probability Distributions",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\n\n\n\n\n\n\n\nExpected Value\n\n\nThe expected value/mean of the binomial distribution with \\(n\\) trials and success probability \\(p\\) is \\(E(X) = np\\).\n\n\n\n\n\n\n\n\n\n\n\nVariance\n\n\nThe variance of the binomial distribution with \\(n\\) trials and success probability \\(p\\) is \\(V(X) = np(1-p)\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-5",
    "href": "lecture4.html#example-5",
    "title": "Probability Distributions",
    "section": "Example",
    "text": "Example\nIn the Philippines, the estimated percentage of individuals who received booster shots for COVID-19 is 19.7%.\n\nQuestionAnswer\n\n\nFor a sample of 2,500 Philippine residents, what is the expected value of Philippine residents who received a booster? What is the variance of the associated binomial distribution?\n\n\nExpected Value: \\(E(X) = 2500(0.197)=\\) 492.5\nVariance: \\(V(X) = 2500(0.197)(1-0.197)=\\) 395.4775",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#exercise-3",
    "href": "lecture4.html#exercise-3",
    "title": "Probability Distributions",
    "section": "Exercise",
    "text": "Exercise\nIn 2021, 8.9% of US adults were diagnosed with diabetes (Types I and II) CDC.\n\nQuestionsAnswers\n\n\nFor a sample of 250 adults in 2021, what is the expected number of diagnosed diabetics? What is the variance of the distribution?\n\n\nExpected Value: \\(E(X) = 250(0.089)=\\) 22.25\nVariance: \\(V(X) = 250(0.089)(1-0.089)=\\) 20.26975",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#poisson-distribution",
    "href": "lecture4.html#poisson-distribution",
    "title": "Probability Distributions",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\nThe Poisson distribution is often used to model the count of events occurring in an interval of time or space. These events are assumed to have a very low probability of occurrence in a small interval.\n\n\n\n\n\n\nNote\n\n\nExamples include number of cars stopped at an intersection for an hour, radioactive particles that decay in a given period of time, and number of hospitalizations in a day.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#poisson-process",
    "href": "lecture4.html#poisson-process",
    "title": "Probability Distributions",
    "section": "Poisson Process",
    "text": "Poisson Process\nThe Poisson distribution results from a set of assumptions about an underlying process called the Poisson process.\n\n\n\n\n\n\nImportant\n\n\nThe Poisson process has the following characteristics\n\nThe occurrence of an event in an interval of space or time has no effect on the probability of a second occurrence of the event in the same or other interval.\nAn infinite number of occurrences of the event must be possible in the interval\nThe probability of a single occurrence of the event in a given interval is proportional to the length of the interval.\nIn any infinitesimally small portion of the interval, the probability of more than one occurrence of the event is negligible.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#poisson-distribution-1",
    "href": "lecture4.html#poisson-distribution-1",
    "title": "Probability Distributions",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\nThe PMF for the Poisson distribution is defined by the parameter \\(\\lambda\\).\n\\[\np(x) =\\frac{\\lambda^x e^{-\\lambda}}{x!}; x = 0,1,2,...\n\\]\n\n\n\n\n\n\nNote\n\n\n\\(e\\) is Euler’s number, \\(\\lambda\\) is the Poisson rate parameter describing the average number of events per unit interval.\\(\\lambda\\) must be positive.\nThe notation for a Poisson distribution with a Poisson rate parameter \\(\\lambda\\) is \\(X \\sim POIS(\\lambda)\\).\n\n\n\n\n\n\n\n\n\nImportant\n\n\nThe Poisson distribution can approximate a binomial distribution with large \\(n\\) and small \\(p\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#poisson-distribution-r",
    "href": "lecture4.html#poisson-distribution-r",
    "title": "Probability Distributions",
    "section": "Poisson Distribution: R",
    "text": "Poisson Distribution: R\nR is also capable of calculating the PMF, CDF, and simulating data for a Poisson process.\n\nExponentialPMFCDFRandom\n\n\nThe exp(lambda) can calculate the \\(e^{-\\lambda}\\) term in the Poisson PMF.\n\n\ndpois(x,lambda) calculates the value of the PMF for \\(X=x\\), i.e. \\(P(X=x) = p(x)\\).\n\n\nppois(x,lambda) calculates the value of the CDF for \\(X=x\\), i.e. \\(P(X\\leq x) = F(x)\\).\n\n\nrpois(k,lambda) draws k values from a random variable \\(X \\sim POIS(\\lambda)\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#poisson-distribution-visualization",
    "href": "lecture4.html#poisson-distribution-visualization",
    "title": "Probability Distributions",
    "section": "Poisson Distribution: Visualization",
    "text": "Poisson Distribution: Visualization\n\nPOIS(1)POIS(2.5)POIS(5)",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-6",
    "href": "lecture4.html#example-6",
    "title": "Probability Distributions",
    "section": "Example",
    "text": "Example\nOn a weekday, the expected number of people in the waiting room of a small clinic is 14.\n\nQuestionsAnswersSimulations\n\n\n\nWhat is the probability that there will be exactly 20 people in the waiting room on a weekday?\nWhat is the probability that there will be at most 10 people in the waiting room on a weekday?\nSimulate 150 weekdays using rpois(). Create a histogram for the number of people in the waiting room from the 150 simulations.\n\n\n\n\nExactly 20 people\n\n\ndpois(20,14)\n\n[1] 0.02859653\n\n\n\nAt most 10 people\n\n\nppois(10,14)\n\n[1] 0.1756812\n\n\n\n\n\nNsim&lt;- 150 # Simulating 10 times\nset.seed(12345)\nsims &lt;- rpois(Nsim,14)\ndf &lt;- data.frame(simulations=sims)\nggplot(df, aes(x=simulations)) + \n  geom_histogram(binwidth=1) + \n  theme_bw() + \n  labs(x=\"Number of People in the Waiting Room\", y=\"Count\")",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#exercise-4",
    "href": "lecture4.html#exercise-4",
    "title": "Probability Distributions",
    "section": "Exercise",
    "text": "Exercise\nThe hourly number of pedestrians waiting by a bus stop is estimated to be 7.\n\nQuestionsAnswersSimulations/Random Draws\n\n\n\nWhat is the probability of observing exactly 7 pedestrians at the bus stop?\nwhat is the probability of observing at least 10 pedestrians at the bus stop?\nDraw 1000 values from the associated Poisson distribution using rpois. Create a histogram for the randomly drawn values.\n\n\n\n\nExactly 7 pedestrians\n\n\ndpois(7,7)\n\n[1] 0.1490028\n\n\n\nAt least 10 pedestrians: Complement of at most 9 pedestrians! Hence, the probability is equal to \\(1-P(X \\leq 9) = 1-F(9)\\)\n\n\n1-ppois(9,7)\n\n[1] 0.1695041\n\n\n\n\n\nNsim&lt;- 1000 # Simulating 10 times\nset.seed(12)\nsims &lt;- rpois(Nsim,14)\ndf &lt;- data.frame(simulations=sims)\nggplot(df, aes(x=simulations)) + \n  geom_histogram(bins=50) + \n  theme_bw() + \n  labs(x=\"Number of Diagnosed Diabetics\", y=\"Count\")",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#expected-value-and-variance-1",
    "href": "lecture4.html#expected-value-and-variance-1",
    "title": "Probability Distributions",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\nThe expected value and variance of the Poisson distribution are equal and is given by the rate parameter \\(\\lambda\\), i.e. \\(E(X) = \\lambda, V(X) = \\lambda\\).\n\n\n\n\n\n\nImportant\n\n\nIf we are interested in the expected value for \\(t\\) units of time, then the expected value is given by \\(E(X) = \\lambda t\\).\n\n\n\n\n\n\n\n\n\nImportant\n\n\nThe equality between expected value and variance can be restrictive because data variability cannot be controlled such that this equality can hold.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-7",
    "href": "lecture4.html#example-7",
    "title": "Probability Distributions",
    "section": "Example",
    "text": "Example\nThe hourly number of pedestrians waiting by a bus stop is estimated to be 7.\n\nQuestionsAnswers\n\n\n\nWhat is the expected value of the number of pedestrians waiting by the bus stop after one hour?\nWhat is the variance of the associated Poisson distribution?\nWhat is the expected value of the number of pedestrians waiting by the bus stop after 30 minutes?\n\n\n\n\nAfter one hour, \\(E(X) = \\lambda t = (7)(1)=\\) 7\nVariance: \\(V(X) = \\lambda =\\) 7\nAfter 30 minutes, \\(E(X) = \\lambda t = (7)(0.5)=\\) 3.5",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#other-discrete-distributions",
    "href": "lecture4.html#other-discrete-distributions",
    "title": "Probability Distributions",
    "section": "Other Discrete Distributions",
    "text": "Other Discrete Distributions\n\n\n\n\n\n\n\nHypergeometric Distribution\n\n\nConsider a population size \\(N\\) and a sample size \\(n\\). Each element in the population can be categorized into a “success” or failure. If there are \\(r\\) successes in the population, the probability that \\(x\\) successes will be drawn in a sample of size \\(n\\) is given by the hypergeometric distribution.\nThis distribution is used in exact tests such as the Fisher’s Exact Test.\n\n\n\n\n\n\n\n\n\n\n\nNegative Binomial Distribution\n\n\nThe negative binomial distribution is used to model counts for overdispersed data and other biological processes. Overdispersion occurs when the data set exhibits more variability than what a statistical model expects. Recall that the Poisson distribution is restricted by the property that the mean is equal to the variance.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#continuous-random-variables",
    "href": "lecture4.html#continuous-random-variables",
    "title": "Probability Distributions",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\n\n\n\n\n\n\n\nContinuous Random Variable\n\n\nA random variable is continuous if it can only take on values in one or more intervals of the real line.\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nTime, distance, weight, and volume are examples of continuous variables.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#continuous-probability-distributions",
    "href": "lecture4.html#continuous-probability-distributions",
    "title": "Probability Distributions",
    "section": "Continuous Probability Distributions",
    "text": "Continuous Probability Distributions\n\n\n\n\n\n\nNote\n\n\nRecall that probabilities from discrete random variables are found by summing PMF values.\n\n\n\nFor continuous random variables, summing becomes integration.\n\n\n\n\n\n\nTip\n\n\nImagine creating a histogram with an infinite amount of narrow bins. Adding these values eventually lead to a sum of the areas under the curve.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#probability-density-functions",
    "href": "lecture4.html#probability-density-functions",
    "title": "Probability Distributions",
    "section": "Probability Density Functions",
    "text": "Probability Density Functions\nThe continuous probability distribution can be expressed as a probability density function (PDF), denoted by \\(f_X(x)\\) or \\(f(x)\\).\n\n\n\n\n\n\nWarning\n\n\nThere are important differences between probability density functions and probability mass functions (discrete). For example, for continuous variables,\n\\(P(X=x) = 0 \\neq f(x)\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#cumulative-distribution-functions",
    "href": "lecture4.html#cumulative-distribution-functions",
    "title": "Probability Distributions",
    "section": "Cumulative Distribution Functions",
    "text": "Cumulative Distribution Functions\nRecall that the cumulative distribution function (CDF) is given by \\(F_X(x) = P(X \\leq x)\\). The CDF is mathematically defined as:\n\\[\nF_X(x) = \\int_{-\\infty}^x f(x)dx\n\\]\n\n\n\n\n\n\nTip\n\n\nSince \\(P(X=x) = 0\\), it also follows that\n\\[\nP(a \\leq x \\leq b) = P(a &lt; x \\leq b) = P(a \\leq x &lt; b) =  P(a &lt; x &lt; b)\n\\]\nand that\n\\[\nF_X(x) = P(X \\leq x) = P(X&lt;x)\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#probabilities-for-continuous-random-variables",
    "href": "lecture4.html#probabilities-for-continuous-random-variables",
    "title": "Probability Distributions",
    "section": "Probabilities for Continuous Random Variables",
    "text": "Probabilities for Continuous Random Variables\nInstead of \\(P(X=x)\\), we are more interested in the probability that a continuous random variable assumes a value between \\(a\\) and \\(b\\), denoted by \\(P(a &lt; X &lt; b)\\), which can be calculated as:\n\\[\nP(a &lt; X &lt; b) = \\int_a^b f(x)dx = F(b)-F(a)\n\\]\n\n\n\n\n\n\nNote\n\n\nProbability density functions have the following properties\n\n\\(f(x) \\geq 0\\) for \\(-\\infty &lt; x &lt; \\infty\\).\n\\(\\int_{-\\infty}^{\\infty} f(x)dx = 1\\) or \\(F(\\infty)=1\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#uniform-distribution-pdf",
    "href": "lecture4.html#uniform-distribution-pdf",
    "title": "Probability Distributions",
    "section": "Uniform Distribution: PDF",
    "text": "Uniform Distribution: PDF\nThe uniform distribution has a constant PDF such that\n\\[\nf(x) = \\begin{cases}\n      \\frac{1}{\\theta_2-\\theta_1},~ \\theta_1 \\leq x \\leq \\theta_2; \\theta_2&gt;\\theta_1 \\\\\n      0, ~ otherwise\n   \\end{cases}\n\\]\nA random variable \\(X\\) that has a uniform distribution on the interval \\([\\theta_1,\\theta_2]\\) is denoted as \\(X\\sim UNIF(\\theta_1,\\theta_2)\\).\n\n\n\n\n\n\nNote\n\n\nA uniform distribution is defined by two parameters: \\(\\theta_1\\) and \\(\\theta_2\\). A standard uniform distribution is a special case such that \\(\\theta_1\\)=0, \\(\\theta_2\\)=1.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#uniform-distribution-visualization",
    "href": "lecture4.html#uniform-distribution-visualization",
    "title": "Probability Distributions",
    "section": "Uniform Distribution: Visualization",
    "text": "Uniform Distribution: Visualization",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#uniform-distribution-probabilities",
    "href": "lecture4.html#uniform-distribution-probabilities",
    "title": "Probability Distributions",
    "section": "Uniform Distribution: Probabilities",
    "text": "Uniform Distribution: Probabilities\n\n\n\n\n\n\nImportant\n\n\nLucky for you, there’s no expectations of any calculus in class.\n\n\n\nThe probability \\(P(a&lt;X&lt;b)\\) if \\(X\\sim UNIF(\\theta_1,\\theta_2)\\) can be calculated using the following equation:\n\\[\nP(a &lt; X &lt; b) = \\frac{b-a}{\\theta_2-\\theta_1}\n\\]\nwhere \\(a,b\\) are assumed to be between \\(\\theta_1 &lt; a \\leq b &lt; \\theta_2\\).\n\n\n\n\n\n\nImportant\n\n\nThis result can also be demonstrated using geometry!",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#uniform-distribution-probabilities-in-r",
    "href": "lecture4.html#uniform-distribution-probabilities-in-r",
    "title": "Probability Distributions",
    "section": "Uniform Distribution: Probabilities in R",
    "text": "Uniform Distribution: Probabilities in R\nIn R, punif(x,min,max) can calculate the probability \\(P(X \\leq x) = P(\\theta_1&lt;X &lt; x)\\). Hence, if we want to calculate \\(P(a &lt; X &lt; b)\\) when \\(X\\sim UNIF(\\theta_1,\\theta_2)\\),\nP(a &lt; X &lt; b) = punif(b,theta_1,theta_2)-punif(a,theta_1,theta_2)\n\n\n\n\n\n\nImportant\n\n\nYou can also draw random numbers from a uniform distribution \\(UNIF(\\theta_1,\\theta_2)\\) using runif(#sims,theta_1,theta_2)",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-8",
    "href": "lecture4.html#example-8",
    "title": "Probability Distributions",
    "section": "Example",
    "text": "Example\nSuppose \\(X \\sim UNIF(0,5)\\). What is the probability that an outcome \\(x\\) is between 0.25 and 4?\n\nMathR\n\n\na = 0.25, b=4, \\(\\theta_1 = 0, \\theta_2=5\\).\n\\[\nP(a &lt; X &lt; b) = \\frac{b-a}{\\theta_2-\\theta_1} = \\frac{4-0.25}{5-0}\n\\]\nHence, P(a &lt; X &lt; b) = 0.75\n\n\n\npunif(4,0,5) - punif(0.25,0,5)\n\n[1] 0.75",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#exercise-5",
    "href": "lecture4.html#exercise-5",
    "title": "Probability Distributions",
    "section": "Exercise",
    "text": "Exercise\nSuppose \\(X \\sim UNIF(0,100)\\).\n\nQuestionAnswer\n\n\nWhat is the probability that an outcome \\(x\\) is between 55 and 85?\n\n\n\\[\n\\frac{85-55}{100-0}=0.30\n\\]\n\npunif(85,0,100) - punif(55,0,100)\n\n[1] 0.3",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#uniform-distribution-expected-value-and-variance",
    "href": "lecture4.html#uniform-distribution-expected-value-and-variance",
    "title": "Probability Distributions",
    "section": "Uniform Distribution: Expected Value and Variance",
    "text": "Uniform Distribution: Expected Value and Variance\nFor the uniform distribution, the mean is given by \\(E(X) = \\frac{\\theta_1+\\theta_2}{2}\\). The variance is given by \\(E(X) = \\frac{(\\theta_2+\\theta_1)^2}{12}\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#gaussian-distribution",
    "href": "lecture4.html#gaussian-distribution",
    "title": "Probability Distributions",
    "section": "Gaussian Distribution",
    "text": "Gaussian Distribution\nThe Gaussian distribution, also known as the normal distribution, is an important distribution in statistics.\n\n\n\n\n\n\nNote\n\n\nMany natural physical and human-related phenomena closely follow a normal distribution.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#gaussian-distribution-pdf",
    "href": "lecture4.html#gaussian-distribution-pdf",
    "title": "Probability Distributions",
    "section": "Gaussian Distribution: PDF",
    "text": "Gaussian Distribution: PDF\nThe probability density function of the Gaussian distribution can be expressed as:\n\\[\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}; -\\infty &lt; x &lt; \\infty\n\\]\n\n\n\n\n\n\nNote\n\n\nA uniform distribution is defined by two parameters: the mean \\(\\mu\\) and \\(\\sigma^2\\). A random variable \\(X\\) that has a Gaussian distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\) is denoted as \\(X\\sim N(\\mu,\\sigma^2)\\).\n\n\n\n\n\n\n\n\n\nImportant\n\n\nA standard normal distribution is a special case such that \\(\\mu\\)=0, \\(\\sigma^2\\)=1. Variables that follow a standard normal distribution are often denoted as \\(Z\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#gaussian-distribution-characteristics",
    "href": "lecture4.html#gaussian-distribution-characteristics",
    "title": "Probability Distributions",
    "section": "Gaussian Distribution: Characteristics",
    "text": "Gaussian Distribution: Characteristics\nThe Gaussian distribution has the following characteristics:\n\nThe distribution is symmetric about the mean \\(\\mu\\).\nThe mean, median, and mode are all equal.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#gaussian-distribution-visualization",
    "href": "lecture4.html#gaussian-distribution-visualization",
    "title": "Probability Distributions",
    "section": "Gaussian Distribution: Visualization",
    "text": "Gaussian Distribution: Visualization\n\nSame Means, Changing VarianceSame Variance, Changing Means",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#gaussian-distribution-r",
    "href": "lecture4.html#gaussian-distribution-r",
    "title": "Probability Distributions",
    "section": "Gaussian Distribution: R",
    "text": "Gaussian Distribution: R\n\n\n\n\n\n\nImportant\n\n\nCalculating probabilities mathematically would be impossible without calculus. However, R makes life easy for us.\n\n\n\n\nPDFCDFSimulating/Generating Random VariablesCDF to X/Z\n\n\nYou can calculate the PDF value for a normal distribution, f(x), using dnorm(x,mean,sd). Note that the function uses standard deviation, not variance.\n\n\nYou can calculate the CDF value for a normal distribution, F(x), using pnorm(x,mean,sd). Note that the function uses standard deviation, not variance.\n\n\nYou can simulate/generate random Gaussian variables using rnorm(#sims,mean,sd). Note that the function uses standard deviation, not variance.\n\n\nIf we know the value of \\(F(x)\\), we can determine what \\(x\\) is using qnorm(F(x),mean, sd). If the mean and standard deviation/variance is unknown, we can get the corresponding value of the standard normal distribution \\(Z\\) by specifying mean=0 and sd=1.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-9",
    "href": "lecture4.html#example-9",
    "title": "Probability Distributions",
    "section": "Example",
    "text": "Example\nFor a random variable \\(Z~N(0,1)\\) following the standard normal distribution\n\nQuestionAnswer\n\n\nCalculate the following probabilities using R\n\n\\(P(Z \\leq 1)\\)\n\\(P(Z \\geq 2.5)\\)\n\\(P(-2 &lt; Z &lt; 2)\\)\n\n\n\n\n\\(P(Z \\leq 1) = F(1)\\)\n\n\npnorm(1,0,1)\n\n[1] 0.8413447\n\n\n\n\\(P(Z\\geq 2.5) = 1- P(Z&lt;2.5) = 1-F(2.5)\\)\n\n\n1-pnorm(2.5,0,1)\n\n[1] 0.006209665\n\npnorm(2.5,0,1,lower.tail=FALSE)\n\n[1] 0.006209665\n\n\n\n\\(P(-2 &lt; Z &lt; 2) = F(2)-F(-2)\\)\n\n\npnorm(2,0,1) - pnorm(-2,0,1)\n\n[1] 0.9544997",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#exercise-6",
    "href": "lecture4.html#exercise-6",
    "title": "Probability Distributions",
    "section": "Exercise",
    "text": "Exercise\nConsider \\(X \\sim N(3,9)\\).\n\nQuestionAnswer\n\n\n\n\\(P(X \\leq 6)\\)\n\\(P(X \\geq 3)\\)\n\\(P(-3 &lt; X &lt; 9)\\)\n\n\n\nNote that \\(\\sigma^2=9\\), so sd=3.\n\n\\(P(X \\leq 6)\\)\n\n\npnorm(6,3,3)\n\n[1] 0.8413447\n\n\n\n\\(P(X \\geq 10.5)\\)\n\n\n1- pnorm(10.5,3,3)\n\n[1] 0.006209665\n\npnorm(10.5,3,3,lower.tail=F)\n\n[1] 0.006209665\n\n\n\n\\(P(-3 &lt; X &lt; 9)\\)\n\n\npnorm(9,3,3) - pnorm(-3,3,3)\n\n[1] 0.9544997\n\n\n\n\n\n\n\n\nImportant\n\n\nNote that the answers are the same!",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#other-continuous-distributions",
    "href": "lecture4.html#other-continuous-distributions",
    "title": "Probability Distributions",
    "section": "Other Continuous Distributions",
    "text": "Other Continuous Distributions\n\n\n\n\n\n\n\nWeibull Distribution\n\n\nThe Weibull distribution is used to model random variables that are constrained to be positive, such as lifetimes, impurities, etc. This is common for epidemic modeling and survival analysis.\n\n\n\n\n\n\n\n\n\n\n\nStatistical tests\n\n\nContinuous distributions that you will learn about in future chapters are the \\(t\\) distribution, \\(F\\) distribution, and the \\(\\chi^2\\) (chi-squared) distribution.",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#standardization",
    "href": "lecture4.html#standardization",
    "title": "Probability Distributions",
    "section": "Standardization",
    "text": "Standardization\nA common transformation employed with Gaussian distributed variables is standardization. Standardization involves rescaling the variable based on the mean, \\(\\mu\\), and variance \\(\\sigma^2\\), of the distribution. An observation \\(X\\) can be standardized into a standardized variable \\(Z\\) using the following equation:\n\\[\nZ = \\frac{X-\\mu}{\\sigma}\n\\]\n\n\n\n\n\n\nImportant\n\n\nIf \\(X \\sim(\\mu,\\sigma^2)\\), then \\(Z\\sim N(0,1)\\). The CDF of the normal distribution is referred to by \\(\\Phi(z) = P(Z \\leq z)\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#standard-normal-distribution-implications",
    "href": "lecture4.html#standard-normal-distribution-implications",
    "title": "Probability Distributions",
    "section": "Standard Normal Distribution: Implications",
    "text": "Standard Normal Distribution: Implications\n\n\n\n\n\n\nNote\n\n\nThe random variable \\(Z\\) calculates how many standard deviations away the observation is from the mean. The transformation also implies that\n\\[\nP(a &lt; X &lt; b) = P \\left(\\frac{a-\\mu}{\\sigma} &lt; Z &lt; \\frac{b-\\mu}{\\sigma}\\right)\n\\]\nand\n\\[\nF(x) = \\Phi \\left(z=\\frac{x-\\mu}{\\sigma}\\right)\n\\]",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-10",
    "href": "lecture4.html#example-10",
    "title": "Probability Distributions",
    "section": "Example",
    "text": "Example\nThe results of a biostatistics aptitude test was found to be normally distributed with a mean score of 78.5 and variance of 120.\n\nWhat is the probability that somebody scores above 92 points?\nGenerate 1000 draws from the corresponding normal distribution using rnorm() and create a histogram from the generated values.\n\n\nNo standardizationStandardizationSimulation/Generation\n\n\n\npnorm(92,78.5,sqrt(120),lower.tail=F)\n\n[1] 0.1089044\n\n\n\n\n\\(Z = \\frac{X-\\mu}{\\sigma}\\) = 1.2323758\n\npnorm((92-78.5)/sqrt(120),0,1,lower.tail=F)\n\n[1] 0.1089044\n\n\n\n\n\nset.seed(12345)\ndf &lt;- data.frame(x=rnorm(1000,mean=78.5,sd=sqrt(120)))\n\nggplot(df,aes(x=x)) + \n  geom_histogram(binwidth=1) +\n  theme_bw() + \n  labs(x=\"Generated Scores\",\n       y=\"Count\")",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#exercise-7",
    "href": "lecture4.html#exercise-7",
    "title": "Probability Distributions",
    "section": "Exercise",
    "text": "Exercise\nThe waiting time for physician appointments in a hospital was normally distributed with mean equal to 23.5 minutes and standard deviation of 6.7 minutes. What is the probability that a patient will wait less than five minutes for an appointment?\n\nQuestionAnswer\n\n\n\nUse standardization to calculate the standardized variable \\(z\\) such that \\(P(X&lt;5) = P(Z &lt; z)\\).\nCalculate the probability using the standardization method.\n\n\n\n\\(z = \\frac{5-23.5}{6.7}\\) = -2.761194\n\npnorm((5-23.5)/6.7,0,1)\n\n[1] 0.002879523",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#implications",
    "href": "lecture4.html#implications",
    "title": "Probability Distributions",
    "section": "Implications",
    "text": "Implications\nFor every random variable \\(X \\sim N(\\mu,\\sigma^2)\\), the probability of an outcome to be within one standard deviation of the mean can be written as:\n\\[\nP((\\mu-\\sigma) &lt; X &lt; (\\mu+\\sigma)) = P(-1 &lt; Z &lt;1)\n\\]\n\npnorm(1,0,1) - pnorm(-1,0,1)\n\n[1] 0.6826895\n\n\n\n\n\n\n\n\nNote\n\n\nWe expect 68.3% of the measurements of the random variable \\(X\\) is within one standard deviation of the mean (\\(\\pm 1\\sigma\\))",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#implications-1",
    "href": "lecture4.html#implications-1",
    "title": "Probability Distributions",
    "section": "Implications",
    "text": "Implications\nSimilarly, we can calculate the probability within \\(\\pm 2\\sigma\\) and \\(\\pm 3\\sigma\\). Around 95.4% of the outcomes are \\(\\pm 2\\sigma\\), while 99.7% of the outcomes are \\(\\pm 3\\sigma\\). This is why it is sometimes assumed that normally distributed data should be found within three standard deviations from the mean.\n\n\\(\\pm 2 \\sigma\\)\\(\\pm 3 \\sigma\\)\n\n\n\npnorm(2,0,1) - pnorm(-2,0,1)\n\n[1] 0.9544997\n\n\n\n\n\npnorm(3,0,1) - pnorm(-3,0,1)\n\n[1] 0.9973002",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#calculating-z-from-phiz",
    "href": "lecture4.html#calculating-z-from-phiz",
    "title": "Probability Distributions",
    "section": "Calculating \\(z\\) from \\(\\Phi(z)\\)",
    "text": "Calculating \\(z\\) from \\(\\Phi(z)\\)\nThe function qnorm(prob) provides the value for \\(z\\) such that the CDF \\(\\Phi(z) = P(Z \\leq z) = prob\\).",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-11",
    "href": "lecture4.html#example-11",
    "title": "Probability Distributions",
    "section": "Example",
    "text": "Example\nFind \\(z\\) such that \\(\\Phi(z) = 0.93\\).\n\nqnorm(0.93)\n\n[1] 1.475791",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#example-2-1",
    "href": "lecture4.html#example-2-1",
    "title": "Probability Distributions",
    "section": "Example 2",
    "text": "Example 2\nConsider a random distribution with mean 5 and standard deviation 2.7. What is the 90th percentile of the distribution?\n\nThe 90th percentile, \\(p_{90}\\), can be expressed as \\(P(X \\leq p_{90}) = 0.90\\). \\(p_{90}\\) can be calculated using qnorm.\n\n\nqnorm(0.90,mean=5,sd=2.7)\n\n[1] 8.460189",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lecture4.html#exercise-8",
    "href": "lecture4.html#exercise-8",
    "title": "Probability Distributions",
    "section": "Exercise",
    "text": "Exercise\nSuppose the total cholesterol values for a certain population are approximately normally distributed with a mean of 205.7 mg/100ml with a standard deviation of 23.5 mg/100ml.\n\nQuestionsAnswer\n\n\n\nWhat is the probability that an individual picked at random will have\n\nAbove 200 mg/100ml?\nBetween 150 and 200 mg/100ml?\n\nWhat is the cholesterol level such that only 5% of the population have cholesterol levels above this amount?\n\n\n\n\nAbove 200 mg/100ml\n\n\npnorm(200,mean=205.7,sd=23.5)\n\n[1] 0.4041758\n\n\n\nBetween 150 and 200 mg/100ml\n\n\npnorm(200,mean=205.7,sd=23.5) - pnorm(150,mean=205.7,sd=23.5)\n\n[1] 0.3952868\n\n\n\nOnly 5% of the population have cholesterol levels above this amount: \\(p_{95}\\)\n\n\nqnorm(0.95,mean=205.7,sd=23.5)\n\n[1] 244.3541",
    "crumbs": [
      "Lectures",
      "Lecture 4- Probability Distributions"
    ]
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "EAB 703 Lectures",
    "section": "",
    "text": "This website provides the slides for EAB 703-1002 for Dr. Miguel Fudolig. Content is mainly based on the following books:\n\nDaniel, W. W., & Cross, C. L. (2018). Biostatistics: a foundation for analysis in the health sciences. John Wiley & Sons.\nRigdon, S. E., Fricker Jr, R. D., & Montgomery, D. C. (2024). Introduction to Probability and Statistics for Data Science: with R. Cambridge University Press.\nIsmay, C., Kim, A.Y., & Valdivia, A. (2025). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (2nd ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9781032724546",
    "crumbs": [
      "Lectures"
    ]
  },
  {
    "objectID": "PS1_key.html",
    "href": "PS1_key.html",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "The data set Arrests can be accessed through the package car inR. The data set includes data on police treatment of individuals arrested in Toronto for simple possession of small quantities of marijuana. The data are part of a larger data set featured in a series of articles in the Toronto Star newspaper.\n\n\nProvide the relevant R code to install the car package in R.\n\ninstall.packages(\"car\")\n\nProvide the relevant R code to load the car package.\n\n\nlibrary(car)\n\nLoading required package: carData\n\n\n\nExplore the Arrests data set using glimpse() to show the different variables available in the data set. What are the different variables in the Arrests data set? Show your code. [4pts.]\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::recode() masks car::recode()\n✖ purrr::some()   masks car::some()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nglimpse(Arrests)\n\nRows: 5,226\nColumns: 8\n$ released &lt;fct&gt; Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes…\n$ colour   &lt;fct&gt; White, Black, White, Black, Black, Black, White, White, Black…\n$ year     &lt;int&gt; 2002, 1999, 2000, 2000, 1999, 1998, 1999, 1998, 2000, 2001, 1…\n$ age      &lt;int&gt; 21, 17, 24, 46, 27, 16, 40, 34, 23, 30, 18, 18, 17, 42, 26, 2…\n$ sex      &lt;fct&gt; Male, Male, Male, Male, Female, Female, Male, Female, Male, M…\n$ employed &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Ye…\n$ citizen  &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Ye…\n$ checks   &lt;int&gt; 3, 3, 3, 1, 1, 0, 0, 1, 4, 3, 0, 3, 1, 0, 2, 3, 4, 5, 3, 0, 0…\n\n\n\nCreate a frequency table for the year of arrests (year variable). Which year had the most arrests? Show your code. [2pts.]\n\n\nlibrary(summarytools)\n\n\nAttaching package: 'summarytools'\n\n\nThe following object is masked from 'package:tibble':\n\n    view\n\nfreq(Arrests$year)\n\nError in match(x, table, nomatch = 0L): 'match' requires vector arguments\n\n\nWarning in parse_call(mc = match.call(), caller = \"freq\"): metadata extraction\nterminated unexpectedly; inspect results carefully\n\n\nFrequencies  \n\n              Freq   % Valid   % Valid Cum.   % Total   % Total Cum.\n----------- ------ --------- -------------- --------- --------------\n       1997    492      9.41           9.41      9.41           9.41\n       1998    877     16.78          26.20     16.78          26.20\n       1999   1099     21.03          47.23     21.03          47.23\n       2000   1270     24.30          71.53     24.30          71.53\n       2001   1211     23.17          94.70     23.17          94.70\n       2002    277      5.30         100.00      5.30         100.00\n       &lt;NA&gt;      0                               0.00         100.00\n      Total   5226    100.00         100.00    100.00         100.00\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe year with the most arrests was 2000.\n\n\n\nCreate a bar plot to visualize the frequencies of arrests for each year using ggplot() and geom_bar(). Show your code. [2pts.]\n\nAcceptable solution (full credit):\n\nggplot(data=Arrests,aes(x=year)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nBetter solution:\n\nggplot(data=Arrests,aes(x=as.factor(year))) +\n  geom_bar(color=\"black\") + \n  theme_bw() + \n  labs(x=\"Year\", y=\"Frequency\")\n\n\n\n\n\n\n\n\n\nThe file SleepHealthData.csv comprises 400 rows and 13 columns, covering a wide range of variables related to sleep and daily habits. It includes details such as gender, age, occupation, sleep duration, quality of sleep, physical activity level, stress levels, BMI category, blood pressure, heart rate, daily steps, and the presence or absence of sleep disorders.\n\n\nProvide the relevant R code to import SleepHealthData.csv into R and assign it to the variable sleep.\n\n\n\n\n\n\n\nImportant\n\n\n\nSave the CSV file in the same folder as your Rscript!\n\n\ngetwd() # provides your working directory\n\nsleep &lt;- read.csv(\"SleepHealthData.csv\")\n\n\nComplete the following table for the recorded heart rate of the participants. Show your code.\n\nMean:\n\nmean(sleep$heart_rate)\n\n[1] 70.16578\n\n\nMedian:\n\nmedian(sleep$heart_rate)\n\n[1] 70\n\n\nRange:\n\nmax(sleep$heart_rate)-min(sleep$heart_rate)\n\n[1] 21\n\n\nVariance and Standard Deviation:\n\nvar(sleep$heart_rate)\n\n[1] 17.10381\n\nsd(sleep$heart_rate)\n\n[1] 4.135676\n\n\nMinimum and Maximum:\n\nmin(sleep$heart_rate)\n\n[1] 65\n\nmax(sleep$heart_rate)\n\n[1] 86\n\n\n\\(Q_1\\), \\(Q_3\\), and IQR:\n\nquantile(sleep$heart_rate,0.25)\n\n25% \n 68 \n\nquantile(sleep$heart_rate,0.75)\n\n75% \n 72 \n\nIQR(sleep$heart_rate)\n\n[1] 4\n\n\n\nCreate a histogram for the recorded heart rate of all the participants using ggplot() and geom_histogram(). Show your code.\n\nAcceptable (full credit):\n\nggplot(data=sleep, aes(x=heart_rate)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nBetter version:\n\nggplot(data=sleep, aes(x=heart_rate)) + \n  geom_histogram(color=\"white\", binwidth=2.5, fill=\"black\") + \n  theme_bw() +\n  labs(x=\"Heart Rate Measurement\")\n\n\n\n\n\n\n\n\n\nCreate a boxplot for the recorded heart rate of all the participants grouped by gender using ggplot() and geom_boxplot(). Show your code. (Hint: Use x=gender in the aes() function.)\n\nAcceptable (full credit):\n\nggplot(data=sleep, aes(x=gender,y=heart_rate)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nBetter version:\n\nggplot(data=sleep, aes(x=gender, y=heart_rate)) + \n  geom_boxplot() + \n  theme_bw() + \n  labs(x=\"Gender\",y=\"Heart Rate Measurement\")",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1 Key"
    ]
  }
]