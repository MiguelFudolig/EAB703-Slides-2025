{
  "hash": "56985a6a1ef0fe6646c279ed16d95ca7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hypothesis Testing: Tests Involving Variances\"\nsubtitle: Lecture 7.1\nformat:\n  revealjs:\n    theme: clean.scss\n    scrollable: true\n    footer: \"Lecture 7.1 - [Back to home](https://madfudolig.quarto.pub/introtobiostats/)\"\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n    slide-number: true\n    menu: true\n    code-annotations: hover\n    chalkboard: true\n    engine: knitr\n    echo: true\n    code-fold: false\n    \n  pdf: \n    number-sections: true\n    engine: knitr\nbibliography: references.bib\n---\n\n# Outline\n\n- Ratio of Population Variance Tests\n- Association vs. Causation\n\n\n## Hypothesis Test: Ratio of Population Variances\n\n Unlike the comparisons done in this chapter, comparing two population variances are usually based on the ratio of the variances ($\\sigma_1^2/\\sigma_2^2$).\n\n::: callout-note\nWhen $\\sigma_1^2/\\sigma_2^2=1$, the variances are equal. However, this ratio can not be negative, which is not consistent with the distributions we have considered (standard normal distribution and t-distribution)\n:::\n\n## F-distribution\n\nThe F-distribution is a distribution that has the following characteristics:\n\n- Defined in the range 0 < X < $\\infty$\n- Defined by two degrees of freedom: the numerator degrees of freedom, $df_{num}$ or $df_1$, and the denominator degrees of freedom, $df_{den}$ or $df_2$.\n\nIn `R`, the following functions can be used to generate the properties of the *central* F-distribution.\n\n- `df(x,df1,df2)`: PDF\n- `pf(x,df1,df2)`: CDF\n- `qf(p,df1,df2)`: Calculates F value for a given probability\n- `rf(n,df1,df2)`: Generates $n$ samples from the F-distribution\n\n## Hypothesis Test: Ratio of Population Variances\n\nIf we are interested in testing the null hypothesis $H_0: \\sigma_1/\\sigma_2 = 1$, the alternative hypothesis can be one of the following:\n\n-   One-sided hypotheses: $H_a: \\sigma_1/\\sigma_2 < 1$ or $H_a: \\sigma_1/\\sigma_2 > 1$.\n-   Two-sided hypotheses: $H_a: \\sigma_1/\\sigma_2 \\neq 1$\n\nThe problem dictates which alternative is appropriate.\n\n## Test Statistic\n\nAssuming the following assumptions hold: $s_1^2$ and $s_2^2$ are computed from independent samples of size $n_1$ and $n_2$, respectively drawn from two normally distributed populations. \n\nThe quantity $\\frac{s_1^2/\\sigma_1^2}{s_2^2/\\sigma_2^2}$ follows the F-distribution with degrees of freedom $(df_1,df_2) = (n_1-1,n_2-1)$. Under the null hypothesis, $\\sigma_1^2/\\sigma_2^2 = 1$. Hence, our test statistic is expressed as:\n\n$$\nF=S_1^2/S_2^2 \\sim F(n_1-1,n_2-1)\n$$\n\n## Rejection Region \n\nWe will use the F-distribution to define the rejection region and the corresponding p-values.\n\n\nFor one-sided tests, the rejection region is defined by the range:\n\n$$\nF < F_{1-\\alpha}(n_1-1,n_2-1)\n$$\n\nAs much as possible, we set the group with the expected larger variance to be in the numerator to avoid complications in calculating the rejection region. \n\nFor two-sided tests, the rejection region is defined by the ranges:\n\n$$\nF < F_{\\alpha/2}(n_1-1,n_2-1)~ or~ F > F_{1-\\alpha/2}(n_1-1,n_2-1)\n$$\n\n::: callout-note\nThe p-values can be calculated using statistical software like `R` and follows the same rejection rules as the previous tests (reject $H_0$ when $p < \\alpha$)\n:::\n\n## Hypothesis Testing: `R`\n\nThe function `var.test()` provides the test statistic and the corresponding p-values for testing the ratio between population variances. Typically, we are interested in the null hypothesis of equality or $H_0: \\sigma_1^2/\\sigma_2^2 = 1$. \n\nThe function can be implemented in two ways. If the data is stored in a data frame `df`,\n\n::: callout-note\n`var.test(formula,data=df,ratio=1,alternative)` can be used if the groups are defined by a column in `df` and the response variable is defined by another column in `df`. The formula can be expressed as `response~group`. `alternative` can take on the following values: `\"two.sided\"`, `\"less\"`, or `\"greater\"`\n:::\n\n::: callout-note\n`var.test(x,y,ratio=1,alternative)` can be used if the responses/measurements from each group are found in different columns in `df`. Suppose the measurements are in the columns `group1` and `group2`. The groups `x` and `y` can be expressed as `x=df$group1,y=df$group2`. `alternative` can take on the following values: `\"two.sided\"`, `\"less\"`, or `\"greater\"`.\n:::\n\n::: callout-note\nTo determine the rejection region for the $F$ statistic, we can use the `qf()` function.\n:::\n\n## Example\n\nConsider the sleep health data set from `SleepHealthData.csv`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep <- read.csv(\"SleepHealthData.csv\")\n```\n:::\n\n\n\n::: panel-tabset\n### Question\n\nPerform a hypothesis test to determine if there is evidence of unequal variances between the average sleep duration of males and females. Assume equal variances and a significance level of 0.05.\n\n### Answer\n\nThe parameter of interest is the ratio of the variances in sleep duration between females and males. The corresponding hypotheses are:\n\n$$\nH_0: \\sigma_f^2/\\sigma_m^2 = 1;H_0: \\sigma_f^2/\\sigma_m^2 \\neq 1\n$$\nWe can now use the `var.test()` function to solve for the test statistic and p-value. Note that the groups are defined by the `gender` variable and the response is defined by the `sleep_duration` variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nftest <- var.test(sleep_duration~gender,\n         data=sleep,\n         ratio=1,\n         alternative=\"two.sided\"\n         )\n\nftest\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  sleep_duration by gender\nF = 1.6095, num df = 184, denom df = 188, p-value = 0.001242\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 1.206633 2.147875\nsample estimates:\nratio of variances \n           1.60951 \n```\n\n\n:::\n:::\n\n\nThe test statistic value is 1.6095104 corresponding to a p-value of 0.0012421. The rejection region can be calculated using the `qf()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalpha<- 0.05\nlower_bound <- qf(alpha/2,df1=184,df2=188)\nlower_bound\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.74935\n```\n\n\n:::\n\n```{.r .cell-code}\nupper_bound<- qf(1-alpha/2,df1=184,df2=188)\nupper_bound\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.333886\n```\n\n\n:::\n:::\n\n\nThe rejection region is defined as: F<0.74935 or F>1.3338859. The test statistic is in this rejection region, hence, we reject the null hypothesis. There is sufficient evidence that the ratio of the two population variances is not equal to one, implying that the population variances are unequal.\n\n::: callout-note\nThe same decision and conclusion is reached when the p-value is used.\n:::\n\n:::\n\n## Exercise\n\nConsider the sleep health data set from `SleepHealthData.csv`.\n\n:::: panel-tabset\n### Question\n\nRecall that you were asked to assume equal variances in testing for a difference between the average heart rate of males and females in the previous lecture. Perform a hypothesis test to determine if there is sufficient evidence to claim that the population variances of the heart rate of males and females are different. Use a significance level of 0.001.\n\n### Answer\n\nThe parameter of interest is the ratio of the variances between females and males. The corresponding hypotheses are:\n\n$$\nH_0: \\sigma_f^2/\\sigma_m^2 = 1;H_0: \\sigma_f^2/\\sigma_m^2 \\neq 1\n$$\nWe can now use the `var.test()` function to solve for the test statistic and p-value. Note that the groups are defined by the `gender` variable and the response is defined by the `heart_rate` variable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nftest <- var.test(heart_rate~gender,\n         data=sleep,\n         ratio=1,\n         alternative=\"two.sided\"\n         )\n\nftest\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  heart_rate by gender\nF = 1.4975, num df = 184, denom df = 188, p-value = 0.006088\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 1.122678 1.998430\nsample estimates:\nratio of variances \n          1.497524 \n```\n\n\n:::\n:::\n\n\nThe test statistic value is 1.4975238 corresponding to a p-value of 0.0060876. The rejection region can be calculated using the `qf()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalpha<- 0.001\nlower_bound <- qf(alpha/2,df1=184,df2=188)\nlower_bound\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6150367\n```\n\n\n:::\n\n```{.r .cell-code}\nupper_bound<- qf(1-alpha/2,df1=184,df2=188)\nupper_bound\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.624297\n```\n\n\n:::\n:::\n\n\nThe rejection region is defined as: F<0.6150367 or F>1.6242974. The test statistic is NOT in this rejection region, hence, we fail to reject the null hypothesis. There is insufficient evidence that the ratio of the two population variances is not equal to one.\n\n::: callout-note\nThe same decision and conclusion is reached when the p-value is used.\n:::\n\n# Association vs. Causation\n\n## Association vs. Causation\n\nWhen comparing two groups, it is important to be mindful of how to interpret the conclusion. Suppose we are comparing two groups.When we reject the null hypothesis and conclude that there is sufficient evidence supporting the alternative hypothesis, there is an implied *association* between the groups and the response variable. \n\n::: callout-warning\n**However, this does not necessarily mean that the group variable was the reason why there was a significant difference.** There might be other variables in play, also known as confounding variables, that could be associated with both groups and response variable and contributed to this significant differences. The hypothesis tests discussed do not account for this, hence causation cannot be claimed.\n\nIn experiments, the effects of these confounding variables can be mitigated by performing random assignment of participants to the treatment groups. In observational and retrospective studies, the process to prove causation is much harder. There is a whole field that addresses this problem called *causal inference*, which we will not discuss in this class.\n:::",
    "supporting": [
      "lecture7-1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}